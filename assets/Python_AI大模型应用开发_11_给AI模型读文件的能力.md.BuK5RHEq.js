import{_ as i,c as a,o as n,ah as l}from"./chunks/framework.D5cOWG0Y.js";const g=JSON.parse('{"title":"给AI模型读文件的能力","description":"","frontmatter":{"title":"给AI模型读文件的能力","tags":["Python"],"categories":["Python"]},"headers":[],"relativePath":"Python/AI大模型应用开发/11_给AI模型读文件的能力.md","filePath":"Python/AI大模型应用开发/11_给AI模型读文件的能力.md","lastUpdated":1756401482000}'),e={name:"Python/AI大模型应用开发/11_给AI模型读文件的能力.md"};function h(t,s,p,k,r,d){return n(),a("div",null,[...s[0]||(s[0]=[l(`<h2 id="一、rag-怎么让ai知道私人数据-检索增强生成" tabindex="-1">一、RAG 怎么让AI知道私人数据？检索增强生成 <a class="header-anchor" href="#一、rag-怎么让ai知道私人数据-检索增强生成" aria-label="Permalink to “一、RAG 怎么让AI知道私人数据？检索增强生成”">​</a></h2><p>当大语言模型（LLM）面临 “知识覆盖不足”（如小众领域、未训练数据）或 “实时性缺失” 问题时，<strong>检索增强生成（Retrieval-Augmented Generation，简称 RAG）</strong> 成为关键解决方案。它通过 “连接外部知识库” 让模型基于实时、专属数据生成准确回答，以下从核心问题、实现流程、优劣势对比三方面展开整理：</p><h3 id="_1、rag-的核心应用场景-解决-llm-的固有局限" tabindex="-1">1、RAG 的核心应用场景：解决 LLM 的固有局限 <a class="header-anchor" href="#_1、rag-的核心应用场景-解决-llm-的固有局限" aria-label="Permalink to “1、RAG 的核心应用场景：解决 LLM 的固有局限”">​</a></h3><p>LLM 的知识依赖训练数据，存在天然短板，RAG 正是为弥补这些短板而生：</p><ol><li><strong>小众 / 专业领域知识不足</strong>：若训练数据中某领域文本覆盖少（如特定行业技术文档、学术研究），LLM 无法生成精准回答。</li><li><strong>私有数据无法访问</strong>：企业内部数据（如员工手册、客户档案）、个人私密文档（如日记、医疗记录）不会纳入公开 LLM 的训练数据，LLM 无法直接回答相关问题。</li><li><strong>知识时效性缺失</strong>：LLM 的训练数据有 “截止日期”（如 GPT-4 截止到 2023 年 10 月），无法回答训练后出现的新信息（如 2024 年新政策、新事件）。</li></ol><p>RAG 的核心价值：让 LLM “实时访问外部知识库”，无需重新训练模型，即可基于专属 / 最新数据生成回答，典型应用包括：</p><ul><li>企业知识库问答（如员工查询内部制度）；</li><li>个人文档问答（如基于 PDF 简历回答职业经历）；</li><li>行业专业工具（如基于医疗文献回答病症问题）。</li></ul><h3 id="_2、rag-的实现流程-三步完成-检索-增强-生成" tabindex="-1">2、RAG 的实现流程：三步完成 “检索 - 增强 - 生成” <a class="header-anchor" href="#_2、rag-的实现流程-三步完成-检索-增强-生成" aria-label="Permalink to “2、RAG 的实现流程：三步完成 “检索 - 增强 - 生成””">​</a></h3><p>RAG 的完整流程分为 “数据准备”“相似检索”“结合生成” 三大核心步骤，环环相扣确保模型获取有效外部信息：</p><h4 id="步骤-1-数据准备-离线阶段-——-构建可检索的向量数据库" tabindex="-1">步骤 1：数据准备（离线阶段）—— 构建可检索的向量数据库 <a class="header-anchor" href="#步骤-1-数据准备-离线阶段-——-构建可检索的向量数据库" aria-label="Permalink to “步骤 1：数据准备（离线阶段）—— 构建可检索的向量数据库”">​</a></h4><p>此阶段为后续检索打基础，核心是将 “非结构化外部文档” 转化为 “结构化向量数据”：</p><ol><li>文档加载与分割： <ul><li>加载外部文档（如 PDF、TXT、Word），由于 LLM 上下文窗口有限（无法处理超长文本），需将文档切分成<strong>短文本块</strong>（如每块 200-500 字符），避免信息超出窗口或分割过细导致语义断裂。</li></ul></li><li>文本向量化（嵌入）： <ul><li>通过 “嵌入模型（Embedding Model）” 将每个文本块转化为<strong>固定长度的向量</strong>（如 1536 维数字串）。</li><li>关键特性：向量需保留文本的 “语义 / 语法关联”—— 相似文本的向量在 “向量空间” 中的距离更近（如 “猫抓老鼠” 和 “猫咪捕捉老鼠” 向量距离近），无关文本距离远（如 “猫抓老鼠” 和 “行星运行” 向量距离远），为后续相似检索提供数学依据。</li></ul></li><li>向量存储： <ul><li>将所有文本块的向量存入 “向量数据库”（如 Pinecone、Chroma、FAISS），向量数据库专门优化 “相似性查询” 效率，可快速找到与目标向量最接近的结果。</li></ul></li></ol><h4 id="步骤-2-相似检索-在线阶段-——-匹配用户问题与知识库" tabindex="-1">步骤 2：相似检索（在线阶段）—— 匹配用户问题与知识库 <a class="header-anchor" href="#步骤-2-相似检索-在线阶段-——-匹配用户问题与知识库" aria-label="Permalink to “步骤 2：相似检索（在线阶段）—— 匹配用户问题与知识库”">​</a></h4><p>当用户提出问题时，需从向量数据库中找到最相关的文本块：</p><ol><li><strong>问题向量化</strong>：将用户的问题（如 “这份文档中提到的产品定价策略是什么？”）通过同一嵌入模型转化为向量。</li><li><strong>相似性查询</strong>：向量数据库计算 “问题向量” 与 “所有文本块向量” 的距离，筛选出<strong>距离最近的 Top N 个文本块</strong>（如 Top 3）—— 这些文本块是知识库中与用户问题最相关的内容。</li></ol><h4 id="步骤-3-结合生成-在线阶段-——-llm-基于检索结果生成回答" tabindex="-1">步骤 3：结合生成（在线阶段）—— LLM 基于检索结果生成回答 <a class="header-anchor" href="#步骤-3-结合生成-在线阶段-——-llm-基于检索结果生成回答" aria-label="Permalink to “步骤 3：结合生成（在线阶段）—— LLM 基于检索结果生成回答”">​</a></h4><p>将 “用户问题 + 相关文本块” 合并为提示，传给 LLM 生成精准回答：</p><ol><li><p>构建提示：按 “问题 + 上下文” 格式组合内容，示例：</p><blockquote><p>“基于以下上下文回答问题： 【上下文】文档中提到，2024 年产品定价策略为：基础版 99 元 / 月，专业版 299 元 / 月，企业版按用户数计费（10 人以内 1999 元 / 月，每增加 10 人加 1000 元）。 【问题】这份文档中提到的产品定价策略是什么？”</p></blockquote></li><li><p><strong>LLM 生成回答</strong>：LLM 以 “相关文本块” 为依据，避免依赖自身固有知识，生成与知识库内容一致的准确回答。</p></li></ol><h3 id="_3、rag-与-直接传入全文-的对比-何时该用-rag" tabindex="-1">3、RAG 与 “直接传入全文” 的对比：何时该用 RAG？ <a class="header-anchor" href="#_3、rag-与-直接传入全文-的对比-何时该用-rag" aria-label="Permalink to “3、RAG 与 “直接传入全文” 的对比：何时该用 RAG？”">​</a></h3><p>随着 LLM 上下文窗口增大（如 GPT-4 Turbo 支持 128k Token），部分场景可 “直接将全文 + 问题传给模型”，但 RAG 在特定场景下仍不可替代，二者对比如下：</p><table tabindex="0"><thead><tr><th>维度</th><th>直接传入全文（无 RAG）</th><th>检索增强生成（RAG）</th></tr></thead><tbody><tr><td><strong>适用场景</strong></td><td>知识库规模小（全文可容纳进 LLM 上下文窗口），对细节准确度要求极高</td><td>知识库规模大（超窗口上限）、私有 / 实时数据、需控制成本</td></tr><tr><td><strong>优点</strong></td><td>1. 无文本分割导致的信息损失，回答准确度可能更高；2. 实现逻辑简单（无需向量数据库）</td><td>1. 支持超大规模知识库；2. 响应速度快（仅传相关文本）；3. 成本低（少消耗 Token，可用小窗口模型）</td></tr><tr><td><strong>缺点</strong></td><td>1. 响应慢（模型需处理全文）；2. 成本高（大窗口模型收费贵 + 多消耗 Token）；3. 无法支持超窗口数据</td><td>1. 文本分割可能丢失跨块语义（需优化分割策略）；2. 需额外维护向量数据库，实现复杂度高</td></tr></tbody></table><h3 id="_4、rag-的核心价值总结" tabindex="-1">4、RAG 的核心价值总结 <a class="header-anchor" href="#_4、rag-的核心价值总结" aria-label="Permalink to “4、RAG 的核心价值总结”">​</a></h3><ol><li><strong>无需训练，快速适配新领域</strong>：无需对 LLM 进行微调（Fine-tuning），仅需更新知识库，即可让模型处理新领域问题，降低技术门槛与成本。</li><li><strong>知识可控且可追溯</strong>：回答基于明确的外部文档，可追溯信息来源（如 “回答来自文档第 3 章”），避免 LLM “幻觉”（生成虚假信息）。</li><li><strong>灵活支持私有 / 实时数据</strong>：企业可将内部数据构建为私有知识库，个人可接入私密文档，且能通过更新知识库实现 “知识实时迭代”（如新增 2024 年数据）。</li></ol><p>通过 RAG，可轻松构建 “专属领域 AI 工具”（如法律文档问答、医疗文献解读），或实现 “PDF/Word 文档问答” 等实用功能，是 LLM 落地行业场景的关键技术之一。</p><h2 id="二、document-loader-把外部文档加载进来" tabindex="-1">二、Document Loader 把外部文档加载进来 <a class="header-anchor" href="#二、document-loader-把外部文档加载进来" aria-label="Permalink to “二、Document Loader 把外部文档加载进来”">​</a></h2><p>在 RAG（检索增强生成）流程中，“文档加载器（Document Loader）” 是数据准备的第一步，负责将不同来源、不同格式的内容（如本地文本、PDF、网络资源）统一加载为 LangChain 可处理的<code>Document</code>对象（含文本内容与元数据）。LangChain 社区提供了丰富的加载器，覆盖主流文档格式与资源类型，以下从核心概念、常用加载器实战、扩展类型三方面展开整理：</p><h3 id="_1、文档加载器的核心概念" tabindex="-1">1、文档加载器的核心概念 <a class="header-anchor" href="#_1、文档加载器的核心概念" aria-label="Permalink to “1、文档加载器的核心概念”">​</a></h3><h4 id="_1-1-核心作用" tabindex="-1">1.1. 核心作用 <a class="header-anchor" href="#_1-1-核心作用" aria-label="Permalink to “1.1. 核心作用”">​</a></h4><p>将非结构化 / 结构化数据（如 TXT、PDF、网页内容）转化为<strong>标准化的<code>Document</code>对象列表</strong>，每个<code>Document</code>包含两个关键属性：</p><ul><li><code>page_content</code>：文本内容本身（字符串），是后续分割、嵌入的核心数据；</li><li><code>metadata</code>：元数据（字典），记录文本的来源信息（如文档路径、页码、URL、语言等），用于追溯数据来源或筛选内容。</li></ul><h4 id="_1-2-设计优势" tabindex="-1">1.2. 设计优势 <a class="header-anchor" href="#_1-2-设计优势" aria-label="Permalink to “1.2. 设计优势”">​</a></h4><ul><li><strong>格式统一</strong>：无论原始数据是 TXT、PDF 还是网页，加载后均为<code>Document</code>对象，后续分割、嵌入步骤无需适配不同格式，降低开发成本；</li><li><strong>来源广泛</strong>：支持本地文件、网络资源、数据库等多种数据源，满足不同场景的知识库构建需求。</li></ul><h3 id="_2、常用文档加载器实战" tabindex="-1">2、常用文档加载器实战 <a class="header-anchor" href="#_2、常用文档加载器实战" aria-label="Permalink to “2、常用文档加载器实战”">​</a></h3><h4 id="_2-1-textloader-加载纯文本文件-txt" tabindex="-1">2.1. TextLoader：加载纯文本文件（TXT） <a class="header-anchor" href="#_2-1-textloader-加载纯文本文件-txt" aria-label="Permalink to “2.1. TextLoader：加载纯文本文件（TXT）”">​</a></h4><p>纯文本文件（如<code>.txt</code>）无格式干扰，是最基础的数据源，<code>TextLoader</code>可直接读取其内容。</p><p>使用步骤</p><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 1. 导入TextLoader</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_community.document_loaders </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> TextLoader</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 2. 初始化加载器：传入TXT文件路径</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">loader </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> TextLoader(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;demo.txt&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 替换为你的TXT文件路径</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 3. 执行加载：返回Document对象列表</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">documents </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> loader.load()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 4. 查看加载结果</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;加载的Document数量：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(documents)</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">第一个Document元素的文本内容：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">documents[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].page_content</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 查看第一个Document元素的文本内容</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">第一个Document的内容：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">documents[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].page_content[:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">200</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">...&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 打印前200字符</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">第一个Document的元数据：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">documents[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].metadata</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 元数据（含文件路径等）</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div><p>关键说明：</p><ul><li>若 TXT 文件较大（如万字以上），<code>load()</code>会返回一个包含 1 个<code>Document</code>的列表（整文件为一个文本块），后续需通过文本分割器切分为更小的块；</li><li>元数据默认包含<code>source</code>（文件路径），可用于追溯文本来源。</li></ul><h4 id="_2-2-pypdfloader-加载-pdf-文件" tabindex="-1">2.2. PyPDFLoader：加载 PDF 文件 <a class="header-anchor" href="#_2-2-pypdfloader-加载-pdf-文件" aria-label="Permalink to “2.2. PyPDFLoader：加载 PDF 文件”">​</a></h4><p>PDF 文件含格式信息（如页码、字体、排版），需依赖<code>PyPDF</code>库解析文本，<code>PyPDFLoader</code>会按页码拆分文本，每一页对应一个<code>Document</code>对象。</p><p>安装<code>PyPDF</code>依赖（解析 PDF 的核心库）：</p><div class="language-sh line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> pypdf</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>使用步骤</p><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 1. 导入PyPDFLoader</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_community.document_loaders </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> PyPDFLoader</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 2. 初始化加载器：传入PDF文件路径</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">loader </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> PyPDFLoader(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;report.pdf&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 替换为你的PDF文件路径</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 3. 执行加载：返回按页码拆分的Document列表（一页一个Document）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">documents </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> loader.load()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 4. 查看加载结果</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;PDF总页数（Document数量）：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(documents)</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">第1页Document元素的文本内容：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">documents[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].page_content</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 查看第一个Document元素的文本内容</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">第1页Document的内容：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">documents[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].page_content[:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">200</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">...&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">第1页Document的元数据：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">documents[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].metadata</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 元数据含&quot;page&quot;（页码）、&quot;source&quot;（路径）</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div><p>关键说明</p><ul><li>加载结果中，每个<code>Document</code>对应 PDF 的一页，元数据的<code>page</code>字段标记页码，便于后续定位内容来源；</li><li>若 PDF 含扫描图（非文字内容），<code>PyPDFLoader</code>无法提取文本，需先通过 OCR 工具（如 Tesseract）将图片转为文字，再用<code>TextLoader</code>加载。</li></ul><h4 id="_2-3-wikipedialoader-加载维基百科词条内容" tabindex="-1">2.3. WikipediaLoader：加载维基百科词条内容 <a class="header-anchor" href="#_2-3-wikipedialoader-加载维基百科词条内容" aria-label="Permalink to “2.3. WikipediaLoader：加载维基百科词条内容”">​</a></h4><p>支持直接从维基百科加载指定词条的内容，无需手动复制粘贴，适合构建含权威信息的知识库。</p><p>安装<code>wikipedia</code>依赖（调用维基百科 API 的库）：</p><div class="language-sh line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> wikipedia</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>使用步骤</p><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 1. 导入WikipediaLoader</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_community.document_loaders </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> WikipediaLoader</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 2. 初始化加载器：配置词条、语言、加载数量</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">loader </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> WikipediaLoader(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    query</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;人工智能&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 维基百科词条名（中文/英文均可）</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    lang</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;zh&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,         </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 语言：&quot;zh&quot;（中文）、&quot;en&quot;（英文）等</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    load_max_docs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 最多加载的相关文档数量（避免内容过多）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 3. 执行加载：返回相关词条的Document列表</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">documents </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> loader.load()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 4. 查看加载结果</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;加载的维基百科文档数量：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(documents)</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">第1个Document元素的文本内容：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">documents[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].page_content</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 查看第一个Document元素的文本内容</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i, doc </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> enumerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(documents, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">【文档</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">i</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">】标题：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">doc.metadata[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;title&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;内容预览：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">doc.page_content[:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">300</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">...&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;来源URL：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">doc.metadata[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;source&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 元数据含词条URL</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br></div></div><p>关键参数说明</p><ul><li><code>query</code>：必填，维基百科词条名（如 “牛顿第二定律”“ChatGPT”）；</li><li><code>lang</code>：可选，默认 “en”（英文），需指定 “zh” 获取中文词条；</li><li><code>load_max_docs</code>：可选，默认加载所有相关词条，建议设较小值（如 2-5）避免内容冗余。</li></ul><h3 id="_3、langchain-支持的其他文档加载器-扩展类型" tabindex="-1">3、LangChain 支持的其他文档加载器（扩展类型） <a class="header-anchor" href="#_3、langchain-支持的其他文档加载器-扩展类型" aria-label="Permalink to “3、LangChain 支持的其他文档加载器（扩展类型）”">​</a></h3><p>除上述三种，LangChain 社区还支持数十种文档加载器，覆盖主流格式与资源，部分常用类型如下：</p><table tabindex="0"><thead><tr><th>加载器类型</th><th>适用场景</th><th>依赖库 / 注意事项</th></tr></thead><tbody><tr><td><code>CSVLoader</code></td><td>加载 CSV 表格文件（如 Excel 导出的结构化数据）</td><td>无需额外依赖，支持指定列提取文本</td></tr><tr><td><code>Docx2txtLoader</code></td><td>加载 Word 文档（.docx 格式）</td><td>需安装<code>docx2txt</code>库</td></tr><tr><td><code>UnstructuredPowerPointLoader</code></td><td>加载 PPT 文档（.pptx 格式）</td><td>需安装<code>unstructured</code>库，提取幻灯片文本</td></tr><tr><td><code>WebBaseLoader</code></td><td>加载网页内容（通过 URL）</td><td>需安装<code>beautifulsoup4</code>库，支持解析 HTML</td></tr><tr><td><code>YouTubeLoader</code></td><td>加载 YouTube 视频的字幕内容</td><td>需安装<code>youtube-transcript-api</code>库，支持多语言字幕</td></tr><tr><td><code>GitHubLoader</code></td><td>加载 GitHub 仓库中的代码 / 文档</td><td>需配置 GitHub Token，支持指定仓库 / 文件路径</td></tr></tbody></table><p>查看所有加载器</p><p>可访问 LangChain 官方文档的<a href="https://python.langchain.com/docs/integrations/document_loaders/" target="_blank" rel="noreferrer">Document Loaders 列表</a>，按 “格式”“来源” 筛选所需加载器，每个加载器均有详细使用示例。</p><h3 id="_4、文档加载的通用注意事项" tabindex="-1">4、文档加载的通用注意事项 <a class="header-anchor" href="#_4、文档加载的通用注意事项" aria-label="Permalink to “4、文档加载的通用注意事项”">​</a></h3><ol><li><p><strong>编码问题</strong>：加载 TXT 文件时，若遇编码错误（如中文乱码），可在<code>TextLoader</code>中指定编码格式，示例：</p><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">loader </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> TextLoader(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;demo.txt&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">encoding</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;utf-8&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 常用编码：utf-8、gbk</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div></li><li><p><strong>大文件处理</strong>：加载超大文件（如 100MB 以上的 TXT/PDF）时，建议先分割文件或使用 “流式加载”（部分加载器支持<code>load_incrementally=True</code>），避免内存溢出；</p></li><li><p><strong>元数据利用</strong>：加载后可通过元数据筛选内容（如仅保留 PDF 的第 1-10 页），示例：</p><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 筛选PDF的第1-5页Document</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">filtered_docs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [doc </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> doc </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> documents </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">if</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> &lt;=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> doc.metadata[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;page&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div></li></ol><h2 id="三、text-splitter-上下文窗口有限-文本切成块" tabindex="-1">三、Text Splitter 上下文窗口有限？文本切成块 <a class="header-anchor" href="#三、text-splitter-上下文窗口有限-文本切成块" aria-label="Permalink to “三、Text Splitter 上下文窗口有限？文本切成块”">​</a></h2><p>在 RAG（检索增强生成）流程中，“文本分割” 是衔接 “文档加载” 与 “向量嵌入” 的关键步骤 —— 由于大语言模型（LLM）上下文窗口有限，需将超长文档切分为 “语义完整、长度可控” 的文本块，为后续精准检索和嵌入奠定基础。以下从核心原理、工具选择、参数配置及中文适配展开整理：</p><h3 id="_1、文本分割的核心意义与挑战" tabindex="-1">1、文本分割的核心意义与挑战 <a class="header-anchor" href="#_1、文本分割的核心意义与挑战" aria-label="Permalink to “1、文本分割的核心意义与挑战”">​</a></h3><h4 id="_1-核心意义" tabindex="-1">1. 核心意义 <a class="header-anchor" href="#_1-核心意义" aria-label="Permalink to “1. 核心意义”">​</a></h4><ul><li><strong>适配 LLM 窗口限制</strong>：若文档长度远超模型上下文窗口（如一本 10 万字的书），无法直接传入模型，需分割为短文本块（如每块 500 字符），确保后续能被模型处理。</li><li><strong>保障语义完整性</strong>：分割后的文本块需是 “可理解的最小单元”（如完整句子、段落），避免切分在半句话、关键概念中间，导致 AI 无法理解文本含义。</li></ul><h4 id="_2-核心挑战" tabindex="-1">2. 核心挑战 <a class="header-anchor" href="#_2-核心挑战" aria-label="Permalink to “2. 核心挑战”">​</a></h4><ul><li><strong>避免语义断裂</strong>：若分割符号选择不当（如在 “牛顿第二定律” 中间切分），会破坏文本逻辑，后续检索和生成都会出错。</li><li><strong>平衡长度与连贯性</strong>：文本块过长可能仍超窗口，过短则丢失上下文关联（如仅切分单个短句，无法体现段落逻辑）。</li></ul><h3 id="_2、langchain-核心分割器-recursivecharactertextsplitter-字符递归分割器" tabindex="-1">2、LangChain 核心分割器：RecursiveCharacterTextSplitter（字符递归分割器） <a class="header-anchor" href="#_2、langchain-核心分割器-recursivecharactertextsplitter-字符递归分割器" aria-label="Permalink to “2、LangChain 核心分割器：RecursiveCharacterTextSplitter（字符递归分割器）”">​</a></h3><p>LangChain 中最常用、适配性最强的分割器是<code>RecursiveCharacterTextSplitter</code>（字符递归分割器），其核心逻辑是 “按优先级使用分割符，递归切分直到文本块符合长度要求”，尤其适合处理多格式、多语言文档。</p><h4 id="_1-前期准备-安装与导入" tabindex="-1">1. 前期准备：安装与导入 <a class="header-anchor" href="#_1-前期准备-安装与导入" aria-label="Permalink to “1. 前期准备：安装与导入”">​</a></h4><ul><li><p><strong>安装依赖</strong>：该分割器属于<code>langchain-text-splitters</code>库，需先安装：</p><div class="language-sh line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> langchain-text-splitters</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div></li><li><p><strong>导入模块</strong>：</p><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_text_splitters </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> RecursiveCharacterTextSplitter</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div></li></ul><h4 id="_2-关键参数解析" tabindex="-1">2. 关键参数解析 <a class="header-anchor" href="#_2-关键参数解析" aria-label="Permalink to “2. 关键参数解析”">​</a></h4><p>创建分割器实例时，需配置 4 个核心参数，直接影响分割效果：</p><table tabindex="0"><thead><tr><th>参数名</th><th>作用</th><th>示例值</th></tr></thead><tbody><tr><td><code>chunk_size</code></td><td>单个文本块的最大长度（单位：字符，部分场景可设为 Token 数）</td><td>500</td></tr><tr><td><code>chunk_overlap</code></td><td>相邻文本块的重叠长度（用于保持上下文连贯性，避免分割处信息丢失）</td><td>50</td></tr><tr><td><code>separators</code></td><td>分割符列表（按优先级排序，优先用靠前的分割符切分，失败则尝试下一个）</td><td>中文适配列表</td></tr><tr><td><code>length_function</code></td><td>计算文本长度的函数（默认<code>len</code>，即字符数；可自定义为 Token 计数器）</td><td><code>len</code></td></tr></tbody></table><h5 id="_1-chunk-size与chunk-overlap-平衡长度与连贯性" tabindex="-1">（1）<code>chunk_size</code>与<code>chunk_overlap</code>：平衡长度与连贯性 <a class="header-anchor" href="#_1-chunk-size与chunk-overlap-平衡长度与连贯性" aria-label="Permalink to “（1）chunk_size与chunk_overlap：平衡长度与连贯性”">​</a></h5><ul><li><code>chunk_size</code>：需根据模型上下文窗口调整（如 GPT-3.5 支持 4k Token≈3000 字符，可设<code>chunk_size=2000</code>），演示时可设较小值（如 500）方便测试。</li><li><code>chunk_overlap</code>：通常设为<code>chunk_size</code>的 10%-20%（如<code>chunk_size=500</code>时设<code>overlap=50</code>），确保相邻块在分割处有重叠（如 “第 1 块结尾 50 字符 = 第 2 块开头 50 字符”），避免关键信息断裂。</li></ul><h5 id="_2-separators-适配中文的分割符配置" tabindex="-1">（2）<code>separators</code>：适配中文的分割符配置 <a class="header-anchor" href="#_2-separators-适配中文的分割符配置" aria-label="Permalink to “（2）separators：适配中文的分割符配置”">​</a></h5><p>默认<code>separators</code>为英文场景设计（含空格、英文标点），中文文档需自定义分割符列表，按 “从大到小” 的语义单元排序（优先按段落、再按句子、最后按短句），示例：</p><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 中文适配的分割符列表（优先级从高到低）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">chinese_separators </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n\\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 段落分隔（优先按段落切分）</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,    </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 换行分隔（段落内按换行切分）</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;。&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,    </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 中文句号（句子结束）</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;！&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,    </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 感叹号</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;？&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,    </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 问号</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;，&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,    </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 逗号（短句分隔，尽量避免，仅在必要时使用）</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;、&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,    </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 顿号</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;&quot;</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">       # 空字符串（最后兜底，任意位置切分，避免无法分割）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><ul><li>逻辑：先尝试用 “段落分隔（\\n\\n）” 切分，若单个段落仍超<code>chunk_size</code>，再用 “换行（\\n）”，以此类推，最后用空字符串兜底，确保所有文本都能被分割。</li></ul><h4 id="_3-文本分割实战" tabindex="-1">3. 文本分割实战 <a class="header-anchor" href="#_3-文本分割实战" aria-label="Permalink to “3. 文本分割实战”">​</a></h4><p>以 “加载后的中文文档” 为例，完整分割流程如下</p><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#!pip install langchain_text_splitters</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_community.document_loaders </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> TextLoader</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_text_splitters </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> RecursiveCharacterTextSplitter</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 加载一份中文产品文档</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">loader </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> TextLoader(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;./demo.txt&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">docs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> loader.load()</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 创建中文适配的字符递归分割器</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">text_splitter </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> RecursiveCharacterTextSplitter(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    chunk_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">500</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 单个文本块最大500字符</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    chunk_overlap</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">40</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 相邻块重叠40字符</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # separators=chinese_separators,  # 中文分割符列表</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # length_function=len      # 按字符数计算长度</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    separators</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n\\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;。&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;！&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;？&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;，&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;、&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 执行分割（输入Documents列表，输出分割后的Documents列表）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">texts </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> text_splitter.split_documents(docs)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">texts</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 验证结果（查看分割后的文本块数量与长度）</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># # print(f&quot;分割前文档数：{len(docs)}&quot;)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># print(f&quot;分割后文本块数：{len(texts)}&quot;)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># print(f&quot;第一个文本块长度：{len(texts[0].page_content)}&quot;)  # 应≤500</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br></div></div><div class="language-sh line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[Document(page_content</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;罗浮宫（法语：Musée du Louvre,英语 /ˈluːv(rə)/ ），正式名称为罗浮博物馆，位于法国巴黎市中心的塞纳河边，原是建于12世纪末至13世纪初的王宫，现在是一所综合博物馆，亦是世界上最大的艺术博物馆之一，以及参观人数最多的博物馆，是巴黎中心最知名的地标。\\n\\n罗浮宫的建筑物始建于1190年左右，并在近代曾多次进行扩建，今天所见的模样则一个巨大的翼楼和亭阁建筑群，主要组成部分的总面积则超过60,600平方公尺（652,000平方英尺），馆内永久收藏则包括雕塑、绘画、美术工艺及古代东方、古代埃及和古希腊罗马等7个分类，主要收藏1860年以前的艺术作品与考古文物，罗浮宫博物馆在1793年8月10日开幕起正式对公众开放，平均每天有15,000名游客到此参观，其中65%是外国游客。\\n\\n位置\\n\\n罗浮宫与杜乐丽花园的卫星照片\\n罗浮宫博物馆位于巴黎市中心的卢浮宫内，位于塞纳河右岸，毗邻杜乐丽花园。最近的两个地铁站是皇家宫-罗浮宫站和卢浮-里沃利站，前者有直达地下购物中心 Carrousel du Louvre 的地下通道。&#39;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">,</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> metadata</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">{</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;source&#39;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;./demo.txt&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Document(page_content</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;在1980年代末和1990年代大改建之前，罗浮宫共有好几个街道入口，目前大部分入口已经永久关闭。自1993年以来，博物馆的正门位置位于拿破仑广场金字塔底下的地下空间，游客可以从金字塔本身、旋转阶梯处连接到博物馆的通道。\\n\\n博物馆的参观时间随著时代的推移而变化。自18世纪开放以来，只有艺术家和来自外国的观光游客享有特权参观，这项特权后在1850年代才消失。当博物馆从1793年首次开放时，新历法法国共和历规定了“十天周”（法语：décades），其中前六天为艺术家和外国人访问，后三天为将军访问，民众仅能在最后一天参观，后在在1800年代初期在恢复七天周后，民众在每周只有4小时的时间能在罗浮宫参观，周六和周日则是缩减至下午2点至下午4点期间参观。\\n\\n从1824年开始的一项新规定允许公众在星期日和节假日时参观，然而其他日子只对艺术家和外国游客开放，这种情况到1855年才发生了变化，博物馆更改成除了周一外全天向公众免费开放，直到1922年才开始收费。\\n\\n当前自1946年开始，罗浮宫除了在周二公休和特殊假日外，通常向游客全面开放参观，内部允许使用照相机和录像机，但禁止使用闪光灯。&#39;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">,</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> metadata</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">{</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;source&#39;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;./demo.txt&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">})]</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(texts[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].page_content)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><div class="language-sh line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">罗浮宫（法语：Musée</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> du</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> Louvre,英语</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /ˈluːv</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">rə</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">/</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> ），正式名称为罗浮博物馆，位于法国巴黎市中心的塞纳河边，原是建于12世纪末至13世纪初的王宫，现在是一所综合博物馆，亦是世界上最大的艺术博物馆之一，以及参观人数最多的博物馆，是巴黎中心最知名的地标。</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">罗浮宫的建筑物始建于1190年左右，并在近代曾多次进行扩建，今天所见的模样则一个巨大的翼楼和亭阁建筑群，主要组成部分的总面积则超过60,600平方公尺（652,000平方英尺），馆内永久收藏则包括雕塑、绘画、美术工艺及古代东方、古代埃及和古希腊罗马等7个分类，主要收藏1860年以前的艺术作品与考古文物，罗浮宫博物馆在1793年8月10日开幕起正式对公众开放，平均每天有15,000名游客到此参观，其中65%是外国游客。</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">位置</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">罗浮宫与杜乐丽花园的卫星照片</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">罗浮宫博物馆位于巴黎市中心的卢浮宫内，位于塞纳河右岸，毗邻杜乐丽花园。最近的两个地铁站是皇家宫-罗浮宫站和卢浮-里沃利站，前者有直达地下购物中心</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> Carrousel</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> du</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> Louvre</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 的地下通道。</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><h4 id="_4-分割效果验证" tabindex="-1">4. 分割效果验证 <a class="header-anchor" href="#_4-分割效果验证" aria-label="Permalink to “4. 分割效果验证”">​</a></h4><ul><li><strong>长度合规</strong>：所有分割后的文本块<code>page_content</code>长度均≤<code>chunk_size</code>，无超窗口风险。</li><li><strong>语义完整</strong>：文本块以 “段落、句子” 结尾（如 “。”“！”），无半句话、断裂概念（如不会出现 “牛顿第二定” 这样的不完整短语）。</li></ul><h3 id="_3、文本分割的注意事项" tabindex="-1">3、文本分割的注意事项 <a class="header-anchor" href="#_3、文本分割的注意事项" aria-label="Permalink to “3、文本分割的注意事项”">​</a></h3><p>① 根据文档类型调整参数：</p><ul><li>长文档（如书籍）：<code>chunk_size</code>可设大（如 1000 字符），<code>overlap</code>设 100-200 字符，确保段落逻辑连贯。</li><li>短文档（如新闻稿）：<code>chunk_size</code>可设小（如 300 字符），<code>overlap</code>设 30-50 字符，避免单块过长。</li></ul><p>② 中文与英文分割符区分：</p><ul><li>英文文档可用默认<code>separators</code>（<code>[&quot;\\n\\n&quot;, &quot;\\n&quot;, &quot;. &quot;, &quot; &quot;, &quot;&quot;]</code>），依赖空格和英文句号；</li><li>中文文档必须自定义<code>separators</code>，避免用空格（中文无空格分隔习惯），优先用中文标点和换行。</li></ul><p>③ 长度计算方式选择：</p><ul><li>若需精准匹配模型 Token 限制（如 GPT-4 的 Token 窗口），可将<code>length_function</code>设为 Token 计数器（如<code>tiktoken.encoding_for_model(&quot;gpt-4&quot;).encode</code>），确保<code>chunk_size</code>按 Token 数计算，避免字符数与 Token 数差异导致超窗口。</li></ul><h3 id="_4、后续流程衔接" tabindex="-1">4、后续流程衔接 <a class="header-anchor" href="#_4、后续流程衔接" aria-label="Permalink to “4、后续流程衔接”">​</a></h3><p>文本分割完成后，下一步将进入 “向量嵌入” 阶段 —— 通过嵌入模型（如 OpenAI Embeddings、Sentence-BERT）将每个<code>split_documents</code>中的文本块转化为向量，最终存入向量数据库，为后续 RAG 的 “相似检索” 做准备。</p><h2 id="四、text-embedding-文本变数字-神奇的嵌入向量" tabindex="-1">四、Text Embedding 文本变数字？神奇的嵌入向量 <a class="header-anchor" href="#四、text-embedding-文本变数字-神奇的嵌入向量" aria-label="Permalink to “四、Text Embedding 文本变数字？神奇的嵌入向量”">​</a></h2><p>在 RAG（检索增强生成）流程中，“文本嵌入（Embedding）” 是将 “分割后的文本块” 转化为 “机器可理解的向量” 的核心步骤 —— 通过嵌入模型捕捉文本的语义与语法关系，为后续 “相似性检索” 提供数学基础。以下从核心原理、工具选择、OpenAI Embeddings 实战三方面展开整理：</p><h3 id="_1、文本嵌入的核心原理与价值" tabindex="-1">1、文本嵌入的核心原理与价值 <a class="header-anchor" href="#_1、文本嵌入的核心原理与价值" aria-label="Permalink to “1、文本嵌入的核心原理与价值”">​</a></h3><h4 id="_1-1、什么是文本嵌入" tabindex="-1">1.1、什么是文本嵌入？ <a class="header-anchor" href="#_1-1、什么是文本嵌入" aria-label="Permalink to “1.1、什么是文本嵌入？”">​</a></h4><p>文本嵌入是通过<strong>嵌入模型</strong>将非结构化文本（如句子、段落）转化为<strong>固定长度的数值向量</strong>（如 1536 维、3072 维数字串）的过程。</p><ul><li>关键特性：向量需保留文本的 “语义关联性”—— <ul><li>相似文本（如 “猫抓老鼠” 和 “猫咪捕捉老鼠”）的向量在 “向量空间” 中的距离更近；</li><li>无关文本（如 “猫抓老鼠” 和 “行星运行轨道”）的向量距离更远。</li></ul></li><li>核心价值：将 “文本语义匹配” 转化为 “向量数学计算”（如计算余弦相似度），让向量数据库能快速找到与用户问题最相关的文本块。</li></ul><h4 id="_1-2、langchain-的嵌入逻辑" tabindex="-1">1.2、LangChain 的嵌入逻辑 <a class="header-anchor" href="#_1-2、langchain-的嵌入逻辑" aria-label="Permalink to “1.2、LangChain 的嵌入逻辑”">​</a></h4><p>LangChain 本身不直接实现嵌入功能，而是通过<strong>集成第三方嵌入模型</strong>（如 OpenAI、百度文心一言、Sentence-BERT）提供统一接口，开发者无需关注模型底层细节，只需调用封装好的方法即可完成嵌入。</p><h3 id="_2、主流嵌入模型与工具选择" tabindex="-1">2、主流嵌入模型与工具选择 <a class="header-anchor" href="#_2、主流嵌入模型与工具选择" aria-label="Permalink to “2、主流嵌入模型与工具选择”">​</a></h3><p>常用的嵌入模型分为 “商业模型” 和 “开源模型” 两类，需根据场景选择：</p><table tabindex="0"><thead><tr><th>类型</th><th>代表模型</th><th>特点</th><th>适用场景</th></tr></thead><tbody><tr><td>商业模型</td><td>OpenAI Embeddings（如 text-embedding-3-large）</td><td>语义捕捉精准，API 调用便捷，需付费</td><td>企业级应用、对精度要求高的场景</td></tr><tr><td>开源模型</td><td>Sentence-BERT（如 all-MiniLM-L6-v2）</td><td>免费，可本地部署，精度略低于商业模型</td><td>个人项目、预算有限、数据隐私敏感</td></tr></tbody></table><p>以<strong>OpenAI Embeddings</strong>为例（最常用的商业嵌入模型），讲解具体实现流程。</p><h3 id="_3、openai-embeddings-实战步骤" tabindex="-1">3、OpenAI Embeddings 实战步骤 <a class="header-anchor" href="#_3、openai-embeddings-实战步骤" aria-label="Permalink to “3、OpenAI Embeddings 实战步骤”">​</a></h3><h4 id="_3-1、前期准备-依赖安装与-api-密钥配置" tabindex="-1">3.1、前期准备：依赖安装与 API 密钥配置 <a class="header-anchor" href="#_3-1、前期准备-依赖安装与-api-密钥配置" aria-label="Permalink to “3.1、前期准备：依赖安装与 API 密钥配置”">​</a></h4><h5 id="_1-安装依赖" tabindex="-1">（1）安装依赖 <a class="header-anchor" href="#_1-安装依赖" aria-label="Permalink to “（1）安装依赖”">​</a></h5><p>需安装<code>openai</code>库（用于调用 OpenAI API）和 LangChain 相关模块：</p><div class="language-sh line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> openai</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> langchain-openai</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><h5 id="_2-配置-api-密钥" tabindex="-1">（2）配置 API 密钥 <a class="header-anchor" href="#_2-配置-api-密钥" aria-label="Permalink to “（2）配置 API 密钥”">​</a></h5><ul><li>方式 1：将 API 密钥存入环境变量（推荐，避免硬编码）： <ul><li>Windows：<code>set OPENAI_API_KEY=&quot;你的API密钥&quot;</code></li><li>macOS/Linux：<code>export OPENAI_API_KEY=&quot;你的API密钥&quot;</code></li></ul></li><li>方式 2：在代码中直接传入密钥（仅用于测试，不推荐生产环境）。</li></ul><h4 id="_3-2、初始化-openai-embeddings-实例" tabindex="-1">3.2、初始化 OpenAI Embeddings 实例 <a class="header-anchor" href="#_3-2、初始化-openai-embeddings-实例" aria-label="Permalink to “3.2、初始化 OpenAI Embeddings 实例”">​</a></h4><p>从<code>langchain-openai</code>导入<code>OpenAIEmbeddings</code>，并配置模型参数：</p><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_openai </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> OpenAIEmbeddings</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 初始化嵌入模型实例</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">embeddings </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> OpenAIEmbeddings(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;text-embedding-3-large&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 指定嵌入模型（可替换为text-embedding-3-small等）</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    openai_api_key</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;你的API密钥&quot;</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">      # 若已设环境变量，可省略该参数（自动读取）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><h5 id="关键参数说明" tabindex="-1">关键参数说明： <a class="header-anchor" href="#关键参数说明" aria-label="Permalink to “关键参数说明：”">​</a></h5><ul><li><code>model</code>：嵌入模型名称，OpenAI 官方支持的模型包括： <ul><li><code>text-embedding-3-large</code>：高维度（默认 3072 维），精度高，适合复杂语义匹配；</li><li><code>text-embedding-3-small</code>：低维度（默认 1536 维），速度快、成本低，适合简单场景；</li><li>旧模型（如<code>text-embedding-ada-002</code>）：仍可用，但推荐优先使用 v3 系列。</li></ul></li><li><code>dimensions</code>（可选）：自定义向量维度（仅 v3 系列支持），如<code>dimensions=1024</code>—— 可在 “精度” 和 “存储 / 计算成本” 间平衡（维度越小，向量数据库存储压力越小，检索速度越快）。</li></ul><h4 id="_3-3、文本嵌入核心操作" tabindex="-1">3.3、文本嵌入核心操作 <a class="header-anchor" href="#_3-3、文本嵌入核心操作" aria-label="Permalink to “3.3、文本嵌入核心操作”">​</a></h4><h5 id="_1-单文本-多文本嵌入" tabindex="-1">（1）单文本 / 多文本嵌入 <a class="header-anchor" href="#_1-单文本-多文本嵌入" aria-label="Permalink to “（1）单文本 / 多文本嵌入”">​</a></h5><p>通过<code>embed_query</code>（单文本，常用于用户问题嵌入）或<code>embed_documents</code>（多文本，常用于文本块嵌入）方法实现：</p><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#!pip install openai</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_openai </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> OpenAIEmbeddings</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">embeddings_model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> OpenAIEmbeddings(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;text-embedding-3-large&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 使用其他API，则需要提供额外参数</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># embeddings_model = OpenAIEmbeddings(model=&quot;text-embedding-3-large&quot;,</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#                                     openai_api_key=&quot;&lt;你的API密钥&gt;&quot;,</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#                                     openai_api_base=&quot;https://api.aigc369.com/v1&quot;)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 多文本嵌入（分割后的文本块列表，返回向量列表）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">text_chunks </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;LangChain是一个用于构建LLM应用的框架&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;OpenAI Embeddings可将文本转化为向量&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;RAG流程包括文档加载、分割、嵌入、检索、生成&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 对文本块列表进行嵌入，返回向量列表（每个向量对应一个文本块）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">embeded_result </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> embeddings.embed_documents(text_chunks)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(embeded_result)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><div class="language-sh line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">2</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">embeded_result</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><div class="language-sh line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[[-0.005549268744966659,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  -0.016023970990018652,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  -0.01250122560200001,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  ...]]</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 查看其他结果</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;文本块数量：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(text_chunks)</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;向量数量：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(embeded_result)</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 与文本块数量一致</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;单个向量维度：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(embeded_result[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 如3072（text-embedding-3-large默认）</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 如果希望嵌入向量维度更小，可以通过dimensions参数进行指定</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">embeddings_model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> OpenAIEmbeddings(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;text-embedding-3-large&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dimensions</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1024</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">embeded_result </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> embeddings_model.embed_documents([</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Hello world!&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Hey bro&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(embeded_result[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><div class="language-sh line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">1024</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 单文本嵌入（用户问题，返回单个向量）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">user_query </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;什么是RAG流程？&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">query_embedding </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> embeddings.embed_query(user_query)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;用户问题向量维度：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(query_embedding)</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 与文本块向量维度一致（确保可计算相似度）</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><div class="language-sh line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">1024</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><h5 id="_2-向量的本质" tabindex="-1">（2）向量的本质 <a class="header-anchor" href="#_2-向量的本质" aria-label="Permalink to “（2）向量的本质”">​</a></h5><p><code>chunk_embeddings</code>和<code>query_embedding</code>均为<strong>浮点数列表</strong>，示例（简化）： <code>[0.023, -0.012, 0.056, ..., 0.031]</code>（共 3072 个浮点数，对应 3072 维向量）。 这些数值无直观含义，但通过数学计算（如余弦相似度）可衡量文本间的语义关联。</p><h4 id="_4-嵌入结果的后续用途" tabindex="-1">4. 嵌入结果的后续用途 <a class="header-anchor" href="#_4-嵌入结果的后续用途" aria-label="Permalink to “4. 嵌入结果的后续用途”">​</a></h4><p>文本块的向量（<code>chunk_embeddings</code>）会被存入<strong>向量数据库</strong>（如 Pinecone、Chroma），用户问题的向量（<code>query_embedding</code>）会用于在向量数据库中 “相似性检索”—— 找到与问题向量距离最近的文本块向量，进而获取对应的原始文本块，为 LLM 生成回答提供上下文。</p><h2 id="五、vector-store-向量数据库-ai模型的海马体" tabindex="-1">五、Vector Store 向量数据库，AI模型的海马体 <a class="header-anchor" href="#五、vector-store-向量数据库-ai模型的海马体" aria-label="Permalink to “五、Vector Store 向量数据库，AI模型的海马体”">​</a></h2><p>在 RAG（检索增强生成）流程中，“向量数据库” 是衔接 “文本嵌入” 与 “相似性检索” 的核心组件 —— 它专门存储文本块的向量，并通过 “相似性搜索” 快速匹配用户问题与知识库内容，解决传统数据库无法处理非结构化数据语义匹配的痛点。以下从核心原理、工具实战、检索流程三方面展开整理：</p><h3 id="_1、向量数据库的核心价值-为何不用传统数据库" tabindex="-1">1、向量数据库的核心价值：为何不用传统数据库？ <a class="header-anchor" href="#_1、向量数据库的核心价值-为何不用传统数据库" aria-label="Permalink to “1、向量数据库的核心价值：为何不用传统数据库？”">​</a></h3><p>传统数据库与向量数据库的核心差异在于 “数据类型适配” 和 “查询机制”，向量数据库的优势集中在<strong>非结构化数据的语义匹配</strong>：</p><table tabindex="0"><thead><tr><th>维度</th><th>传统数据库（如 MySQL、PostgreSQL）</th><th>向量数据库（如 FAISS、Chroma、Pinecone）</th></tr></thead><tbody><tr><td><strong>适配数据类型</strong></td><td>结构化数据（如员工 ID、入职日期，有固定格式和字段定义）</td><td>非结构化数据的向量（如文本嵌入向量、图像向量，无固定格式）</td></tr><tr><td><strong>查询机制</strong></td><td>精准匹配（如 “员工 ID=002”“工资 &gt; 5000”），依赖关键词或数值比对</td><td>相似性搜索（如计算向量间余弦相似度），基于语义关联匹配，不依赖精确关键词</td></tr><tr><td><strong>典型场景局限</strong></td><td>无法处理 “语义相似但关键词不同” 的查询（如查 “擅长财务预算”，无法匹配 “预算控制与财务规划经验丰富”）</td><td>擅长处理语义匹配场景，可快速找到与用户问题 “意思相近” 的文本块</td></tr></tbody></table><p><strong>结论</strong>：在 RAG 中，需用向量数据库存储文本块向量，实现 “用户问题→语义匹配→相关文本块” 的高效检索，这是传统数据库无法替代的。</p><h3 id="_2、主流向量数据库与工具选择" tabindex="-1">2、主流向量数据库与工具选择 <a class="header-anchor" href="#_2、主流向量数据库与工具选择" aria-label="Permalink to “2、主流向量数据库与工具选择”">​</a></h3><p>常用的向量数据库分为 “开源本地型” 和 “商业云服务型”，本节以<strong>FAISS</strong>（Facebook 开源，轻量易上手，适合本地测试）为例，讲解具体实现流程：</p><table tabindex="0"><thead><tr><th>类型</th><th>代表数据库</th><th>特点</th><th>适用场景</th></tr></thead><tbody><tr><td>开源本地</td><td>FAISS、Chroma</td><td>免费，可本地部署，无需网络，适合小体量知识库</td><td>个人项目、本地测试、数据隐私敏感场景</td></tr><tr><td>商业云服务</td><td>Pinecone、Weaviate</td><td>支持大规模数据，高可用，需付费</td><td>企业级应用、超大规模知识库</td></tr></tbody></table><h3 id="_3、faiss-向量数据库实战步骤" tabindex="-1">3、FAISS 向量数据库实战步骤 <a class="header-anchor" href="#_3、faiss-向量数据库实战步骤" aria-label="Permalink to “3、FAISS 向量数据库实战步骤”">​</a></h3><h4 id="_3-1-前期准备-依赖安装与导入" tabindex="-1">3.1. 前期准备：依赖安装与导入 <a class="header-anchor" href="#_3-1-前期准备-依赖安装与导入" aria-label="Permalink to “3.1. 前期准备：依赖安装与导入”">​</a></h4><p>安装 FAISS 依赖</p><p>FAISS 提供 CPU 和 GPU 版本，本地测试优先安装 CPU 版本：</p><div class="language- line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span>pip install faiss-cpu langchain-community</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>导入核心模块</p><p>需导入 LangChain 的<code>FAISS</code>向量存储类，以及前期准备好的 “分割后文本块” 和 “嵌入模型实例”：</p><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 导入FAISS向量数据库</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_community.vectorstores </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> FAISS</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_community.document_loaders </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> TextLoader</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 导入前期准备的组件（文本块+嵌入模型）</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_text_splitters </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> RecursiveCharacterTextSplitter  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 已分割好的文本块依赖</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_openai </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> OpenAIEmbeddings  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 已初始化的嵌入模型</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><h4 id="_3-2-文本块向量存储-一键生成并存储向量" tabindex="-1">3.2. 文本块向量存储：一键生成并存储向量 <a class="header-anchor" href="#_3-2-文本块向量存储-一键生成并存储向量" aria-label="Permalink to “3.2. 文本块向量存储：一键生成并存储向量”">​</a></h4><p>LangChain 封装了<code>FAISS.from_documents</code>方法，可自动完成 “文本块嵌入→向量存储” 的全流程，无需手动处理向量生成：</p><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 假设前期已完成文本分割，得到split_documents（分割后的Documents列表）</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 假设已初始化嵌入模型embeddings（如OpenAIEmbeddings实例）</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 1. 生成文本块向量并存储到FAISS数据库</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">vector_db </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> FAISS</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.from_documents(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    documents</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">split_documents,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 分割后的文本块列表（Documents类型）</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    embedding</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">embeddings        </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 嵌入模型实例（用于将文本块转为向量）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># （可选）保存FAISS数据库到本地，后续可直接加载（避免重复嵌入）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">vector_db.save_local(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;faiss_local_db&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 保存到当前目录的faiss_local_db文件夹</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># （可选）从本地加载FAISS数据库</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># vector_db = FAISS.load_local(&quot;faiss_local_db&quot;, embeddings)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div><ul><li><strong>核心逻辑</strong>：<code>from_documents</code>方法会遍历<code>split_documents</code>中的每个文本块，通过<code>embeddings</code>模型生成向量，再将 “向量 + 原始文本块” 一起存入 FAISS 数据库。</li><li><strong>优势</strong>：无需手动调用嵌入模型，LangChain 自动衔接 “嵌入→存储” 流程，简化代码。</li></ul><h4 id="_3-3-相似性检索-找到与用户问题最相关的文本块" tabindex="-1">3.3. 相似性检索：找到与用户问题最相关的文本块 <a class="header-anchor" href="#_3-3-相似性检索-找到与用户问题最相关的文本块" aria-label="Permalink to “3.3. 相似性检索：找到与用户问题最相关的文本块”">​</a></h4><p>向量数据库的核心功能是 “相似性检索”，LangChain 通过 “检索器（Retriever）” 封装检索逻辑，步骤如下：</p><p>（1）创建检索器</p><p>调用向量数据库的<code>as_retriever</code>方法，生成检索器实例，可配置 “返回文本块数量”（默认返回 Top 4）：</p><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 创建检索器，设置返回Top 3个最相关的文本块</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">retriever </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> vector_db.as_retriever(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">search_kwargs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">{</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;k&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">})</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><ul><li><code>search_kwargs={&quot;k&quot;: 3}</code>：控制检索结果数量，k 值越大，返回的相关文本块越多（需平衡 “覆盖度” 与 “精准度”，通常 k=3~5 即可）。</li></ul><p>（2）执行相似性检索</p><p>检索器实现了 LangChain 的<code>Runnable</code>接口，可直接调用<code>invoke</code>方法传入用户问题，返回最相关的文本块列表：</p><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 用户问题（示例：查询与“财务预算”相关的内容）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">user_query </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;如何制定公司的财务预算？&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 执行检索，返回Top 3个相关文本块（Documents列表）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">relevant_chunks </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> retriever.invoke(user_query)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 查看检索结果</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;检索到的相关文本块数量：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(relevant_chunks)</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i, chunk </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> enumerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(relevant_chunks, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">【相关文本块</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">i</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">】&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;内容：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">chunk.page_content</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 原始文本块内容</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;来源：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">chunk.metadata</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)      </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 文本块元数据（如文档路径、页码，可选）</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><p>（3）检索结果说明</p><ul><li>结果排序：<code>relevant_chunks</code>按 “相似度从高到低” 排序，第一个文本块与用户问题语义最接近。</li><li>语义匹配逻辑：检索器通过计算 “用户问题向量” 与 “数据库中所有文本块向量” 的余弦相似度，筛选出相似度最高的文本块，即使关键词不完全匹配（如用户问 “财务预算”，可匹配 “预算控制与财务规划” 相关文本）。</li></ul><h4 id="_3-4-完整代码" tabindex="-1">3.4. 完整代码 <a class="header-anchor" href="#_3-4-完整代码" aria-label="Permalink to “3.4. 完整代码”">​</a></h4><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># -------------------------- 1. 安装依赖（仅首次执行需运行） --------------------------</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 安装FAISS向量数据库的CPU版本（用于本地存储文本向量，轻量易上手）</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># !pip install faiss-cpu</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># -------------------------- 2. 导入核心模块（对应RAG各环节组件） --------------------------</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 1. 文档加载器：从本地加载TXT纯文本文件</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_community.document_loaders </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> TextLoader</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 2. 向量数据库：FAISS，用于存储文本块向量并支持相似性检索</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_community.vectorstores </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> FAISS</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 3. 嵌入模型：OpenAI Embeddings，用于将文本块转化为语义向量</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_openai.embeddings </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> OpenAIEmbeddings</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 4. 文本分割器：递归字符分割器，将长文本切分为语义完整的短文本块</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_text_splitters </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> RecursiveCharacterTextSplitter</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># -------------------------- 3. 步骤1：加载本地TXT文档（RAG-数据准备） --------------------------</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 初始化TextLoader，传入TXT文件路径（需确保文件在当前代码运行目录下）</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 作用：将TXT文件内容加载为LangChain标准的Document对象（含文本内容和元数据）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">loader </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> TextLoader(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;./demo2.txt&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 执行加载操作，返回Document对象列表（1个Document对应整个TXT文件，后续会分割）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">docs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> loader.load()</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># -------------------------- 4. 步骤2：文本分割（RAG-数据处理） --------------------------</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 初始化递归字符分割器，配置分割参数（适配中文文本特性）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">text_splitter </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> RecursiveCharacterTextSplitter(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    chunk_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">500</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,          </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 单个文本块的最大长度（单位：字符），避免超LLM上下文窗口</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    chunk_overlap</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">40</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,        </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 相邻文本块的重叠长度（40字符），保持语义连贯性（如避免分割在句子中间）</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    separators</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n\\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;。&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;！&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;？&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;，&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;、&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 中文适配分割符优先级</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 分割逻辑：优先按段落（\\n\\n）→换行（\\n）→句子结尾（。！？）→短句分隔（，、）→兜底（任意位置）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 执行分割：将加载的Document列表（整个TXT）切分为多个短文本块Document</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 输出texts为分割后的Document列表，每个元素是一个语义完整的短文本块</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">texts </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> text_splitter.split_documents(docs)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># -------------------------- 5. 步骤3：文本嵌入与向量存储（RAG-数据存储） --------------------------</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 初始化OpenAI嵌入模型（需确保环境变量已配置OPENAI_API_KEY，或通过openai_api_key参数传入）</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 作用：将文本块转化为含语义信息的向量（默认text-embedding-3-small模型，1536维向量）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">embeddings_model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> OpenAIEmbeddings()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 1. 将分割后的文本块（texts）通过嵌入模型生成向量</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 2. 自动将“向量+原始文本块”存入FAISS向量数据库</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 输出db为FAISS数据库实例，后续可用于相似性检索</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">db </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> FAISS</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.from_documents(texts, embeddings_model)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># -------------------------- 6. 步骤4：创建检索器（RAG-检索准备） --------------------------</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 将FAISS数据库包装为检索器（Retriever），简化相似性检索调用</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 检索器是LangChain的标准Runnable组件，支持invoke方法快速查询</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">retriever </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> db.as_retriever()</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 可通过search_kwargs配置检索参数，如search_kwargs={&quot;k&quot;:3}（返回Top3相关文本块，默认k=4）</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># -------------------------- 7. 步骤5：相似性检索（RAG-检索执行） --------------------------</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 第一次检索：查询“卢浮宫这个名字怎么来的？”</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># invoke方法会自动完成：问题→向量转化→FAISS相似性计算→返回TopN相关文本块</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">retrieved_docs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> retriever.invoke(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;卢浮宫这个名字怎么来的？&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 打印第一个最相关文本块的内容（page_content为文本块核心内容）</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;【检索结果1：卢浮宫名字由来】&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(retrieved_docs[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].page_content)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;-&quot;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> *</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 50</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 分隔线，便于区分不同查询结果</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 第二次检索：查询“卢浮宫在哪年被命名为中央艺术博物馆”</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">retrieved_docs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> retriever.invoke(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;卢浮宫在哪年被命名为中央艺术博物馆&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 打印第一个最相关文本块的内容</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;【检索结果2：卢浮宫命名为中央艺术博物馆的年份】&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(retrieved_docs[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].page_content)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br></div></div><h3 id="_4、当前-rag-流程进展与后续衔接" tabindex="-1">4、当前 RAG 流程进展与后续衔接 <a class="header-anchor" href="#_4、当前-rag-流程进展与后续衔接" aria-label="Permalink to “4、当前 RAG 流程进展与后续衔接”">​</a></h3><p>截至目前，已完成 RAG 的前两步核心流程：</p><ol><li><strong>数据准备</strong>：文档加载→文本分割→文本嵌入→向量存储（存入 FAISS）；</li><li><strong>相似检索</strong>：用户问题→问题嵌入→向量数据库相似性搜索→返回相关文本块。</li></ol><p>下一步需完成 RAG 的最后一步：<strong>结合生成</strong>—— 将 “用户问题 + 相关文本块” 合并为提示，传给 LLM 生成基于知识库的精准回答。此外，若需实现 “带记忆的连续对话”，还需将检索器与 “对话记忆”“提示模板” 结合，但 LangChain 提供了更简化的方案（如<code>RetrievalChain</code>），无需手动拼接流程。</p><h2 id="六、retrieval-chain-开箱即用的检索增强对话链" tabindex="-1">六、Retrieval Chain 开箱即用的检索增强对话链 <a class="header-anchor" href="#六、retrieval-chain-开箱即用的检索增强对话链" aria-label="Permalink to “六、Retrieval Chain 开箱即用的检索增强对话链”">​</a></h2><p>在完成 “文档加载→分割→嵌入→向量存储→相似检索” 后，核心需求是 “让 AI 结合检索到的外部文档 + 对话记忆生成回答”。LangChain 提供的<code>Conversational Retrieval Chain</code>（检索增强对话链）已封装好全流程，无需手动拼接 “问题 + 文档 + 记忆”，以下从<strong>核心组件、链创建、使用方法、定制化功能</strong>四方面整理：</p><h3 id="_1、conversational-retrieval-chain-的核心价值" tabindex="-1">1、Conversational Retrieval Chain 的核心价值 <a class="header-anchor" href="#_1、conversational-retrieval-chain-的核心价值" aria-label="Permalink to “1、Conversational Retrieval Chain 的核心价值”">​</a></h3><p>该链是 RAG 与 “对话记忆” 的结合体，解决两大关键问题：</p><ol><li><strong>检索增强</strong>：自动将用户问题对应的 “相关文档片段” 作为上下文传给 AI，避免 AI 依赖固有知识（减少幻觉）；</li><li><strong>对话记忆</strong>：维持多轮对话连贯性，AI 能关联历史对话（如用户追问 “它的具体时间”，AI 知道 “它” 指代上一轮提到的 “卢浮宫命名事件”）。</li></ol><p>相比普通<code>ConversationChain</code>（仅带记忆）或<code>RetrievalChain</code>（仅带检索），它同时具备 “检索外部知识” 和 “记忆上下文” 的能力，是实现 “带知识库的连续对话 AI” 的核心工具。</p><h3 id="_2、链创建前的核心组件准备" tabindex="-1">2、链创建前的核心组件准备 <a class="header-anchor" href="#_2、链创建前的核心组件准备" aria-label="Permalink to “2、链创建前的核心组件准备”">​</a></h3><p>需提前准备 3 个关键组件（均为前序步骤已涉及的内容，可直接复用）：</p><table tabindex="0"><thead><tr><th>组件类型</th><th>作用</th><th>实现方式（示例）</th></tr></thead><tbody><tr><td><strong>聊天模型（LLM）</strong></td><td>生成回答的核心，需支持对话格式</td><td>使用<code>ChatOpenAI</code>（如 GPT-3.5/4）</td></tr><tr><td><strong>检索器（Retriever）</strong></td><td>从向量数据库中检索与问题相关的文档片段</td><td>从 FAISS/Chroma 等向量数据库通过<code>as_retriever()</code>生成</td></tr><tr><td><strong>对话记忆（Memory）</strong></td><td>储存历史对话，维持多轮连贯性</td><td>使用<code>ConversationBufferMemory</code>等记忆类型，需特殊配置</td></tr></tbody></table><h4 id="关键-记忆组件的特殊配置" tabindex="-1">关键：记忆组件的特殊配置 <a class="header-anchor" href="#关键-记忆组件的特殊配置" aria-label="Permalink to “关键：记忆组件的特殊配置”">​</a></h4><p><code>Conversational Retrieval Chain</code>对记忆的<strong>变量名有固定要求</strong>，需确保：</p><ul><li><code>memory_key=&quot;chat_history&quot;</code>：链默认通过<code>chat_history</code>键读取 / 更新历史对话，记忆实例的<code>memory_key</code>必须与此一致；</li><li><code>return_messages=True</code>：记忆需储存为消息对象列表（而非字符串），确保链能正确解析历史对话；</li><li><code>output_key=&quot;answer&quot;</code>：链默认将 AI 的回答存入<code>answer</code>键，记忆需指定该键以更新对话历史。</li></ul><p>示例代码（初始化记忆）：</p><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain.memory </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ConversationBufferMemory</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 初始化符合链要求的记忆实例</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">memory </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ConversationBufferMemory(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    memory_key</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;chat_history&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 必须为&quot;chat_history&quot;，与链的变量名匹配</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    return_messages</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,       </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 储存为消息列表</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    output_key</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;answer&quot;</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">         # 链的输出结果中，AI回答对应&quot;answer&quot;键</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><h3 id="_3、创建-conversational-retrieval-chain" tabindex="-1">3、创建 Conversational Retrieval Chain <a class="header-anchor" href="#_3、创建-conversational-retrieval-chain" aria-label="Permalink to “3、创建 Conversational Retrieval Chain”">​</a></h3><h4 id="_3-1-导入核心模块" tabindex="-1">3.1. 导入核心模块 <a class="header-anchor" href="#_3-1-导入核心模块" aria-label="Permalink to “3.1. 导入核心模块”">​</a></h4><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 导入链、聊天模型、记忆（前序步骤已导入检索器和向量数据库）</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain.chains </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ConversationalRetrievalChain</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain.memory </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ConversationBufferMemory</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_community.document_loaders </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> TextLoader</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_community.vectorstores </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> FAISS</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_openai </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ChatOpenAI</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_openai.embeddings </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> OpenAIEmbeddings</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_text_splitters </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> RecursiveCharacterTextSplitter</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><h4 id="_3-2-初始化其他组件-复用前序代码" tabindex="-1">3.2. 初始化其他组件（复用前序代码） <a class="header-anchor" href="#_3-2-初始化其他组件-复用前序代码" aria-label="Permalink to “3.2. 初始化其他组件（复用前序代码）”">​</a></h4><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># -------------------------- 步骤1：加载文档 --------------------------</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 初始化文本加载器，指定要加载的TXT文件路径</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">loader </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> TextLoader(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;./demo2.txt&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 执行加载，返回包含文档内容的列表（每个元素是一个Document对象）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">docs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> loader.load()</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># -------------------------- 步骤2：文本分割 --------------------------</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 初始化递归字符分割器，配置中文适配参数</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">text_splitter </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> RecursiveCharacterTextSplitter(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    chunk_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">500</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,          </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 单个文本块最大长度（500字符）</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    chunk_overlap</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">40</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,        </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 相邻文本块重叠长度（40字符，保持上下文连贯）</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    separators</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;。&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;！&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;？&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;，&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;、&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 中文分割符优先级</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 将加载的文档分割为多个短文本块</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">texts </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> text_splitter.split_documents(docs)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># -------------------------- 步骤3：创建向量数据库 --------------------------</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 初始化OpenAI嵌入模型（用于将文本转换为向量）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">embeddings_model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> OpenAIEmbeddings()</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 将分割后的文本块转换为向量并存储到FAISS数据库</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">db </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> FAISS</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.from_documents(texts, embeddings_model)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># -------------------------- 步骤4：创建检索器 --------------------------</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 将向量数据库转换为检索器，用于后续查询相关文本块</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">retriever </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> db.as_retriever()</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># -------------------------- 步骤5：初始化核心组件 --------------------------</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 初始化聊天模型（使用GPT-3.5-turbo）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ChatOpenAI(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;gpt-3.5-turbo&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 初始化对话记忆（适配ConversationalRetrievalChain的要求）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">memory </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ConversationBufferMemory(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    return_messages</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,       </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 以消息对象列表形式存储记忆</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    memory_key</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;chat_history&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 记忆在链中的变量名（需与链要求一致）</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    output_key</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;answer&#39;</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">         # 链输出中AI回答的键名（需与链要求一致）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br></div></div><h4 id="_3-3-调用from-llm方法创建链" tabindex="-1">3.3. 调用<code>from_llm</code>方法创建链 <a class="header-anchor" href="#_3-3-调用from-llm方法创建链" aria-label="Permalink to “3.3. 调用from_llm方法创建链”">​</a></h4><p>链的创建通过<code>ConversationalRetrievalChain.from_llm()</code>实现，参数需包含 “模型、检索器、记忆” 三大核心组件：</p><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 创建检索增强对话链</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">qa_chain </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ConversationalRetrievalChain.from_llm(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    llm</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">llm,                </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 聊天模型</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    retriever</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">retriever,    </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 文档检索器</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    memory</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">memory,          </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 对话记忆</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    verbose</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">           # 可选：True则打印链的运行日志，便于调试</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><h3 id="_4、使用链实现-带记忆的-rag-对话" tabindex="-1">4、使用链实现 “带记忆的 RAG 对话” <a class="header-anchor" href="#_4、使用链实现-带记忆的-rag-对话" aria-label="Permalink to “4、使用链实现 “带记忆的 RAG 对话””">​</a></h3><h4 id="_4-1-核心调用方式-invoke方法" tabindex="-1">4.1. 核心调用方式：<code>invoke</code>方法 <a class="header-anchor" href="#_4-1-核心调用方式-invoke方法" aria-label="Permalink to “4.1. 核心调用方式：invoke方法”">​</a></h4><p>链的输入是<strong>含 “question” 键的字典</strong>（<code>question</code>对应用户当前问题），输出是含 “answer”“chat_history” 等键的字典：</p><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 第一轮对话：用户提问（关于外部文档的问题）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">user_question1 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;卢浮宫这个名字怎么来的？&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">response1 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> qa_chain.invoke({</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;chat_history&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: memory, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;question&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: user_question1})</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 查看输出结果</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;用户问题1：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">response1[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;question&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;AI回答1：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">response1[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;answer&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}\\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 第二轮对话：追问（验证记忆，依赖上一轮上下文）</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># user_question2 = &quot;对应的拉丁语是什么呢？&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">user_question2 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;它在哪年被命名为中央艺术博物馆？&quot;</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # “它”指代卢浮宫</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">response2 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> qa_chain.invoke({</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;chat_history&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: memory, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;question&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: user_question2})</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;用户问题2：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">response2[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;question&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;AI回答2：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">response2[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;answer&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;历史对话：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">response2[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;chat_history&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 查看储存的历史对话</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br></div></div><h4 id="_4-2-关键逻辑说明" tabindex="-1">4.2. 关键逻辑说明 <a class="header-anchor" href="#_4-2-关键逻辑说明" aria-label="Permalink to “4.2. 关键逻辑说明”">​</a></h4><ul><li><strong>检索自动触发</strong>：调用<code>invoke</code>时，链会先将<code>question</code>传入检索器，获取相关文档片段，再将 “历史对话（chat_history）+ 问题（question）+ 相关文档” 合并为提示传给 LLM；</li><li><strong>记忆自动更新</strong>：每轮对话后，链会将 “用户问题 + AI 回答” 自动存入<code>memory</code>，无需手动调用<code>save_context</code>；</li><li><strong>上下文连贯性</strong>：第二轮追问中，AI 能识别 “它” 指代 “卢浮宫”，证明记忆生效；同时回答基于检索到的文档片段，证明 RAG 生效。</li></ul><h3 id="_5、链的定制化功能" tabindex="-1">5、链的定制化功能 <a class="header-anchor" href="#_5、链的定制化功能" aria-label="Permalink to “5、链的定制化功能”">​</a></h3><h4 id="_5-1-返回参考文档片段-验证-ai-回答可信度" tabindex="-1">5.1. 返回参考文档片段（验证 AI 回答可信度） <a class="header-anchor" href="#_5-1-返回参考文档片段-验证-ai-回答可信度" aria-label="Permalink to “5.1. 返回参考文档片段（验证 AI 回答可信度）”">​</a></h4><p>默认情况下，链仅返回 AI 的回答，若需验证 “回答是否来自外部文档”（避免幻觉），可在创建链时设置<code>return_source_documents=True</code>：</p><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 创建链时开启“返回参考文档”</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">qa_chain_with_source </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ConversationalRetrievalChain.from_llm(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    llm</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">llm,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    retriever</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">retriever,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    memory</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">memory,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    return_source_documents</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # 开启后，输出会包含&quot;source_documents&quot;键</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 调用并查看参考文档</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">response </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> qa_chain_with_source.invoke({</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;chat_history&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: memory, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;question&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;卢浮宫名字怎么来的？&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">})</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;AI回答：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">response[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;answer&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">【参考文档片段（Top1相关）】&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(response[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;source_documents&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].page_content)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 打印最相关的文档片段</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;文档来源：</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">response[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;source_documents&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].metadata</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 打印文档元数据（如路径、页码）</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div><ul><li>作用：<code>source_documents</code>是检索到的相关文档片段列表（按相似度排序），可直接定位 AI 回答的信息来源，验证回答真实性。</li></ul><h4 id="_5-2-潜在问题-文档片段过长导致超窗口" tabindex="-1">5.2. 潜在问题：文档片段过长导致超窗口 <a class="header-anchor" href="#_5-2-潜在问题-文档片段过长导致超窗口" aria-label="Permalink to “5.2. 潜在问题：文档片段过长导致超窗口”">​</a></h4><p>当前默认逻辑是 “将所有检索到的文档片段（如 Top3）全部传给 LLM”，若片段过长或数量过多，可能超过模型上下文窗口限制。解决方案（后续讲解）包括：</p><ul><li>限制检索片段数量（如<code>retriever = db.as_retriever(search_kwargs={&quot;k&quot;:2})</code>）；</li><li>对检索到的片段进行二次总结（用<code>create_doc_summary</code>参数）；</li><li>使用支持大窗口的模型（如 GPT-4 Turbo 128k）。</li></ul><h3 id="_6、核心流程总结" tabindex="-1">6、核心流程总结 <a class="header-anchor" href="#_6、核心流程总结" aria-label="Permalink to “6、核心流程总结”">​</a></h3><table tabindex="0"><thead><tr><th>步骤</th><th>操作</th><th>链的作用</th></tr></thead><tbody><tr><td>1. 组件准备</td><td>初始化 LLM、Retriever、Memory</td><td>为链提供 “生成核心”“知识来源”“上下文记忆”</td></tr><tr><td>2. 创建链</td><td>调用<code>from_llm</code>整合组件</td><td>封装 “检索→拼接提示→生成回答→更新记忆” 全流程</td></tr><tr><td>3. 发起对话</td><td>调用<code>invoke</code>传入用户问题</td><td>自动触发检索，结合历史对话生成回答，无需手动拼接上下文</td></tr><tr><td>4. 验证 / 定制</td><td>开启<code>return_source_documents</code></td><td>查看参考文档，验证回答可信度，避免 AI 幻觉</td></tr></tbody></table><p>通过<code>Conversational Retrieval Chain</code>，可快速实现 “带知识库 + 带记忆” 的对话 AI（如企业知识库问答、文档助手），是 LangChain 中 RAG 落地的核心工具之一。</p><h2 id="七、documents-chain-把外部文档塞给模型的不同方式" tabindex="-1">七、Documents Chain 把外部文档塞给模型的不同方式 <a class="header-anchor" href="#七、documents-chain-把外部文档塞给模型的不同方式" aria-label="Permalink to “七、Documents Chain 把外部文档塞给模型的不同方式”">​</a></h2><p>在 RAG（检索增强生成）中，“文档传递策略” 决定了如何将检索到的相关文本片段传给 LLM 生成回答。除默认的<code>stuff</code>（填充）法外，LangChain 还支持<code>map_reduce</code>（映射规约）、<code>refine</code>（优化）、<code>map_rerank</code>（映射重排序）3 种策略，分别适配 “片段过长 / 过多”“需精准迭代优化”“需快速筛选最优片段” 等场景。以下从<strong>原理、优缺点、适用场景、代码实现</strong>四方面展开整理：</p><h3 id="_1、4-种文档传递策略核心原理" tabindex="-1">1、4 种文档传递策略核心原理 <a class="header-anchor" href="#_1、4-种文档传递策略核心原理" aria-label="Permalink to “1、4 种文档传递策略核心原理”">​</a></h3><p>所有策略的前提是 “已通过检索器获取 Top N 相关文本片段”，核心差异在于 “片段如何处理并传给 LLM”：</p><h4 id="_1-1-stuff-填充法-默认策略-简单直接" tabindex="-1">1.1. Stuff（填充法）：默认策略，简单直接 <a class="header-anchor" href="#_1-1-stuff-填充法-默认策略-简单直接" aria-label="Permalink to “1.1. Stuff（填充法）：默认策略，简单直接”">​</a></h4><h5 id="原理" tabindex="-1">原理 <a class="header-anchor" href="#原理" aria-label="Permalink to “原理”">​</a></h5><p>将<strong>所有检索到的文本片段拼接成一个长文本</strong>，与用户问题、对话记忆合并为一个提示，一次性传给 LLM 生成回答。</p><ul><li>流程：检索片段 → 拼接片段 → 单次 LLM 调用 → 生成回答。</li></ul><h5 id="优缺点" tabindex="-1">优缺点 <a class="header-anchor" href="#优缺点" aria-label="Permalink to “优缺点”">​</a></h5><table tabindex="0"><thead><tr><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>1. 仅需 1 次 LLM 调用，速度快、成本低；</td><td>1. 片段总长度易超 LLM 上下文窗口限制；</td></tr><tr><td>2. LLM 能看到所有片段的完整关联，信息无割裂；</td><td>2. 仅适合片段数量少（如 Top3）、单片段短的场景。</td></tr></tbody></table><h5 id="适用场景" tabindex="-1">适用场景 <a class="header-anchor" href="#适用场景" aria-label="Permalink to “适用场景”">​</a></h5><ul><li>知识库片段短（如单片段≤500 字符）、检索结果数量少（如 Top2-3）；</li><li>对响应速度和成本敏感，且 LLM 上下文窗口足够容纳所有片段（如 GPT-3.5 4k Token）。</li></ul><h4 id="_1-2-map-reduce-映射规约法-多片段融合" tabindex="-1">1.2. Map Reduce（映射规约法）：多片段融合 <a class="header-anchor" href="#_1-2-map-reduce-映射规约法-多片段融合" aria-label="Permalink to “1.2. Map Reduce（映射规约法）：多片段融合”">​</a></h4><h5 id="原理-1" tabindex="-1">原理 <a class="header-anchor" href="#原理-1" aria-label="Permalink to “原理”">​</a></h5><p>分 “Map（映射）” 和 “Reduce（规约）” 两阶段处理，解决 “片段总长度超窗口” 问题：</p><ol><li><strong>Map 阶段</strong>：将每个检索片段单独传给 LLM，生成该片段对应的 “局部回答”（1 个片段→1 个局部回答，N 个片段→N 次 LLM 调用）；</li><li><strong>Reduce 阶段</strong>：将所有 “局部回答” 拼接成 “回答合集”，传给 LLM 生成 “整合所有信息的最终回答”（1 次 LLM 调用）。</li></ol><ul><li>流程：检索片段 → 逐个片段生成局部回答（Map） → 合并局部回答 → 生成最终回答（Reduce）。</li></ul><h5 id="优缺点-1" tabindex="-1">优缺点 <a class="header-anchor" href="#优缺点-1" aria-label="Permalink to “优缺点”">​</a></h5><table tabindex="0"><thead><tr><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>1. 支持超长篇段 / 多片段（单片段不超窗口即可）；</td><td>1. 需 N+1 次 LLM 调用（N 为片段数），成本高、速度慢；</td></tr><tr><td>2. 能融合多个片段的信息，适合复杂查询；</td><td>2. Reduce 阶段可能遗漏局部回答的细节；</td></tr><tr><td>3. 可并行处理 Map 阶段，提升效率（LangChain 默认支持）。</td><td>3. 局部回答间若有冲突，LLM 需手动判断，易出错。</td></tr></tbody></table><h5 id="适用场景-1" tabindex="-1">适用场景 <a class="header-anchor" href="#适用场景-1" aria-label="Permalink to “适用场景”">​</a></h5><ul><li>检索片段数量多（如 Top5-10）或单片段较长，但每个片段独立包含部分信息；</li><li>需整合多来源信息的复杂查询（如 “总结文档中 3 个产品的定价策略”）。</li></ul><h4 id="_1-3-refine-优化法-迭代式精准优化" tabindex="-1">1.3. Refine（优化法）：迭代式精准优化 <a class="header-anchor" href="#_1-3-refine-优化法-迭代式精准优化" aria-label="Permalink to “1.3. Refine（优化法）：迭代式精准优化”">​</a></h4><h5 id="原理-2" tabindex="-1">原理 <a class="header-anchor" href="#原理-2" aria-label="Permalink to “原理”">​</a></h5><p>按片段顺序<strong>逐次迭代优化回答</strong>，让 LLM 基于新片段不断修正已有回答，而非独立处理每个片段：</p><ol><li>第 1 轮：用 “第 1 个片段 + 用户问题” 生成初始回答；</li><li>第 2 轮：用 “初始回答 + 第 2 个片段 + 用户问题” 生成优化后的回答；</li><li>第 N 轮：用 “上一轮回答 + 第 N 个片段 + 用户问题” 生成最终回答（N 个片段→N 次 LLM 调用）。</li></ol><ul><li>流程：检索片段 → 基于第 1 片段生成初始回答 → 结合第 2 片段优化 → ... → 结合第 N 片段生成最终回答。</li></ul><h5 id="优缺点-2" tabindex="-1">优缺点 <a class="header-anchor" href="#优缺点-2" aria-label="Permalink to “优缺点”">​</a></h5><table tabindex="0"><thead><tr><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>1. 回答精度高，LLM 能基于新信息逐次修正，减少遗漏；</td><td>1. 需 N 次 LLM 调用，成本最高、速度最慢；</td></tr><tr><td>2. 能处理超长篇段 / 多片段，且保留上下文关联；</td><td>2. 片段顺序影响最终结果（若关键片段在后，前期回答易偏差）；</td></tr><tr><td>3. 适合需要深度理解片段逻辑的场景。</td><td>3. 无法并行处理，必须按顺序迭代。</td></tr></tbody></table><h5 id="适用场景-2" tabindex="-1">适用场景 <a class="header-anchor" href="#适用场景-2" aria-label="Permalink to “适用场景”">​</a></h5><ul><li>片段间有逻辑关联（如文档章节顺序），需逐步深入理解的查询（如 “解析论文的实验方法与结论”）；</li><li>对回答精度要求极高，可接受高成本和慢速度（如专业领域问答、学术解读）。</li></ul><h4 id="_1-4-map-rerank-映射重排序法-快速筛选最优" tabindex="-1">1.4. Map Rerank（映射重排序法）：快速筛选最优 <a class="header-anchor" href="#_1-4-map-rerank-映射重排序法-快速筛选最优" aria-label="Permalink to “1.4. Map Rerank（映射重排序法）：快速筛选最优”">​</a></h4><h5 id="原理-3" tabindex="-1">原理 <a class="header-anchor" href="#原理-3" aria-label="Permalink to “原理”">​</a></h5><p>分 “Map（映射）” 和 “Rerank（重排序）” 两阶段，聚焦 “筛选最优片段” 而非 “融合信息”：</p><ol><li><strong>Map 阶段</strong>：将每个检索片段单独传给 LLM，要求 LLM 生成 “局部回答” 并对 “该片段与问题的相关性” 打分（如 1-10 分，N 个片段→N 次 LLM 调用）；</li><li><strong>Rerank 阶段</strong>：筛选出 “相关性得分最高” 的局部回答，直接作为最终回答（无需额外 LLM 调用）。</li></ol><ul><li>流程：检索片段 → 逐个片段生成局部回答 + 打分（Map） → 选择最高分回答作为最终结果（Rerank）。</li></ul><h5 id="优缺点-3" tabindex="-1">优缺点 <a class="header-anchor" href="#优缺点-3" aria-label="Permalink to “优缺点”">​</a></h5><table tabindex="0"><thead><tr><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>1. 相比 Map Reduce，少 1 次 Reduce 调用，成本略低；</td><td>1. 不融合多片段信息，仅用最优片段回答，易遗漏其他信息；</td></tr><tr><td>2. 速度比 Refine 快，且能解决超窗口问题；</td><td>2. 依赖 LLM 打分准确性，若打分偏差，结果会出错；</td></tr><tr><td>3. 适合只需单个片段即可回答的场景。</td><td>3. 需在提示中明确打分规则，提示设计较复杂。</td></tr></tbody></table><h5 id="适用场景-3" tabindex="-1">适用场景 <a class="header-anchor" href="#适用场景-3" aria-label="Permalink to “适用场景”">​</a></h5><ul><li>问题答案仅存在于某一个片段中（如 “文档中提到的卢浮宫命名年份是多少”）；</li><li>需快速得到答案，且可接受 “不融合多片段信息”（如简单事实查询）。</li></ul><h3 id="_2、4-种策略对比总结" tabindex="-1">2、4 种策略对比总结 <a class="header-anchor" href="#_2、4-种策略对比总结" aria-label="Permalink to “2、4 种策略对比总结”">​</a></h3><table tabindex="0"><thead><tr><th>对比维度</th><th>Stuff（填充）</th><th>Map Reduce（映射规约）</th><th>Refine（优化）</th><th>Map Rerank（映射重排序）</th></tr></thead><tbody><tr><td>LLM 调用次数</td><td>1 次</td><td>N+1 次（N 为片段数）</td><td>N 次</td><td>N 次</td></tr><tr><td>响应速度</td><td>最快</td><td>中等（可并行 Map）</td><td>最慢</td><td>中等（可并行 Map）</td></tr><tr><td>成本</td><td>最低</td><td>较高</td><td>最高</td><td>较高</td></tr><tr><td>信息融合能力</td><td>强（全片段可见）</td><td>较强（整合局部回答）</td><td>强（逐次优化）</td><td>弱（仅用最优片段）</td></tr><tr><td>上下文窗口限制</td><td>易超限制</td><td>无（单片段不超即可）</td><td>无（单片段不超即可）</td><td>无（单片段不超即可）</td></tr><tr><td>适用问题类型</td><td>简单事实查询</td><td>复杂多信息整合查询</td><td>深度逻辑理解查询</td><td>单片段事实查询</td></tr></tbody></table><h3 id="_3、代码实现-指定-chain-type" tabindex="-1">3、代码实现：指定 Chain Type <a class="header-anchor" href="#_3、代码实现-指定-chain-type" aria-label="Permalink to “3、代码实现：指定 Chain Type”">​</a></h3><p>在 LangChain 中，通过<code>ConversationalRetrievalChain</code>创建链时，只需给<code>chain_type</code>参数指定对应策略名称，即可切换文档传递方式。以下是完整代码示例（基于前序 RAG 流程）：</p><h4 id="_3-1-前期准备-复用组件" tabindex="-1">3.1. 前期准备（复用组件） <a class="header-anchor" href="#_3-1-前期准备-复用组件" aria-label="Permalink to “3.1. 前期准备（复用组件）”">​</a></h4><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># -------------------------- 导入核心模块 --------------------------</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 检索增强对话链：结合检索、记忆和LLM生成回答</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain.chains </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ConversationalRetrievalChain</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 对话记忆：存储历史对话，支持连续对话</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain.memory </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ConversationBufferMemory</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 文档加载器：加载本地TXT文本文件</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_community.document_loaders </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> TextLoader</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 向量数据库：FAISS，用于存储文本向量并支持相似检索</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_community.vectorstores </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> FAISS</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 聊天模型：OpenAI的对话模型（如GPT-3.5/4）</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_openai </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ChatOpenAI</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 嵌入模型：将文本转换为向量的模型</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_openai.embeddings </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> OpenAIEmbeddings</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 文本分割器：将长文本切分为语义完整的短文本块</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_text_splitters </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> RecursiveCharacterTextSplitter</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># -------------------------- 步骤1：加载文档 --------------------------</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 初始化文本加载器，指定要加载的TXT文件路径</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">loader </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> TextLoader(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;./demo2.txt&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 执行加载，返回包含文档内容的列表（每个元素是一个Document对象）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">docs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> loader.load()</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># -------------------------- 步骤2：文本分割 --------------------------</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 初始化递归字符分割器，配置中文适配参数</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">text_splitter </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> RecursiveCharacterTextSplitter(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    chunk_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">500</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,          </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 单个文本块最大长度（500字符）</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    chunk_overlap</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">40</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,        </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 相邻文本块重叠长度（40字符，保持上下文连贯）</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    separators</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;。&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;！&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;？&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;，&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;、&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 中文分割符优先级</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 将加载的文档分割为多个短文本块</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">texts </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> text_splitter.split_documents(docs)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># -------------------------- 步骤3：创建向量数据库 --------------------------</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 初始化OpenAI嵌入模型（用于将文本转换为向量）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">embeddings_model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> OpenAIEmbeddings()</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 将分割后的文本块转换为向量并存储到FAISS数据库</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">db </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> FAISS</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.from_documents(texts, embeddings_model)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># -------------------------- 步骤4：创建检索器 --------------------------</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 将向量数据库转换为检索器，用于后续查询相关文本块</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">retriever </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> db.as_retriever()</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># -------------------------- 步骤5：初始化核心组件 --------------------------</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 初始化聊天模型（使用GPT-3.5-turbo）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ChatOpenAI(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;gpt-3.5-turbo&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 初始化对话记忆（适配ConversationalRetrievalChain的要求）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">memory </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ConversationBufferMemory(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    return_messages</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,       </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 以消息对象列表形式存储记忆</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    memory_key</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;chat_history&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 记忆在链中的变量名（需与链要求一致）</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    output_key</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;answer&#39;</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">         # 链输出中AI回答的键名（需与链要求一致）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br></div></div><h4 id="_3-2-切换不同-chain-type" tabindex="-1">3.2. 切换不同 Chain Type <a class="header-anchor" href="#_3-2-切换不同-chain-type" aria-label="Permalink to “3.2. 切换不同 Chain Type”">​</a></h4><p>只需修改<code>chain_type</code>参数的值（支持<code>&quot;stuff&quot;</code>“<code>map_reduce</code>”“<code>refine</code>”“<code>map_rerank</code>”）：</p><h5 id="_1-stuff-策略-默认-可省略-chain-type-参数" tabindex="-1">（1）Stuff 策略（默认，可省略 chain_type 参数） <a class="header-anchor" href="#_1-stuff-策略-默认-可省略-chain-type-参数" aria-label="Permalink to “（1）Stuff 策略（默认，可省略 chain_type 参数）”">​</a></h5><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 创建Stuff策略的链</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">qa_chain_stuff </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ConversationalRetrievalChain.from_llm(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    llm</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">llm,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    retriever</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">retriever,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    memory</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">memory,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    chain_type</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;stuff&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 默认值，可省略</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    return_source_documents</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # 可选：返回参考片段</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 调用链</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">response </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> qa_chain_stuff.invoke({</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;question&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;卢浮宫名字怎么来的？&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">})</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Stuff策略回答：&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, response[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;answer&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><h5 id="_2-map-reduce-策略" tabindex="-1">（2）Map Reduce 策略 <a class="header-anchor" href="#_2-map-reduce-策略" aria-label="Permalink to “（2）Map Reduce 策略”">​</a></h5><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">qa_chain_map_reduce </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ConversationalRetrievalChain.from_llm(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    llm</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">llm,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    retriever</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">retriever,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    memory</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">memory,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    chain_type</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;map_reduce&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    return_source_documents</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">response </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> qa_chain_map_reduce.invoke({</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;question&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;总结文档中提到的3个博物馆特点&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">})</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Map Reduce策略回答：&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, response[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;answer&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><h5 id="_3-refine-策略" tabindex="-1">（3）Refine 策略 <a class="header-anchor" href="#_3-refine-策略" aria-label="Permalink to “（3）Refine 策略”">​</a></h5><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">qa_chain_refine </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ConversationalRetrievalChain.from_llm(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    llm</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">llm,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    retriever</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">retriever,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    memory</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">memory,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    chain_type</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;refine&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    return_source_documents</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">response </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> qa_chain_refine.invoke({</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;question&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;解析文档中实验的步骤与结论&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">})</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Refine策略回答：&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, response[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;answer&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><h5 id="_4-map-rerank-策略" tabindex="-1">（4）Map Rerank 策略 <a class="header-anchor" href="#_4-map-rerank-策略" aria-label="Permalink to “（4）Map Rerank 策略”">​</a></h5><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">qa_chain_map_rerank </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ConversationalRetrievalChain.from_llm(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    llm</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">llm,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    retriever</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">retriever,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    memory</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">memory,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    chain_type</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;map_rerank&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    return_source_documents</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 可选：指定打分规则（需与LLM提示匹配）</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    chain_type_kwargs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">{</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;prompt&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;请回答问题，并对该片段与问题的相关性打分（1-10分，格式：回答：xxx；得分：x）&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">response </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> qa_chain_map_rerank.invoke({</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;question&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;卢浮宫在哪年被命名为中央艺术博物馆？&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">})</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Map Rerank策略回答：&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, response[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;answer&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div><h3 id="_4、关键注意事项" tabindex="-1">4、关键注意事项 <a class="header-anchor" href="#_4、关键注意事项" aria-label="Permalink to “4、关键注意事项”">​</a></h3><ol><li><strong>提示模板适配</strong>：<code>map_reduce</code>/<code>refine</code>/<code>map_rerank</code>需 LLM 理解特定指令（如 “生成局部回答”“打分”），LangChain 默认提供基础提示模板，若需定制（如专业领域术语），可通过<code>chain_type_kwargs={&quot;prompt&quot;: 自定义提示}</code>修改。</li><li><strong>片段数量控制</strong>：<code>map_reduce</code>/<code>refine</code>/<code>map_rerank</code>的 LLM 调用次数与片段数（N）正相关，建议通过<code>retriever</code>的<code>search_kwargs={&quot;k&quot;: 3}</code>控制 N（通常 3-5 为宜），平衡精度与成本。</li><li><strong>模型选择</strong>：复杂策略（如<code>refine</code>）建议用更擅长逻辑推理的模型（如 GPT-4），简单策略（如<code>stuff</code>）可用 GPT-3.5 降低成本。</li></ol><p>通过选择合适的文档传递策略，可在 “精度、速度、成本” 之间找到最优平衡，让 RAG 系统适配不同场景的需求（如快速查询、深度分析、多信息整合）。</p>`,275)])])}const c=i(e,[["render",h]]);export{g as __pageData,c as default};
