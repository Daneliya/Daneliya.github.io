import{_ as t,c as o,o as e,aN as l}from"./chunks/framework.CMIDsdwV.js";const _=JSON.parse('{"title":"爬虫的流程","description":"","frontmatter":{"title":"爬虫的流程","tags":["Python"],"categories":["Python"]},"headers":[],"relativePath":"Python/爬虫/1_爬虫的流程.md","filePath":"Python/爬虫/1_爬虫的流程.md","lastUpdated":1767444225000}'),i={name:"Python/爬虫/1_爬虫的流程.md"};function r(n,a,s,d,h,c){return e(),o("div",null,[...a[0]||(a[0]=[l('<div style="display:none;" hidden="true" aria-hidden="true">Are you an LLM? You can read better optimized documentation at /Python\\爬虫\\1_爬虫的流程.md for this page in Markdown format</div><h1 id="爬虫的流程" tabindex="-1">爬虫的流程 <a class="header-anchor" href="#爬虫的流程" aria-label="Permalink to &quot;爬虫的流程&quot;">​</a></h1><p>爬虫是一种通过代码自动获取网页数据的技术，过程简单且应用广泛，但需在合法合规的前提下使用。以下是爬虫的核心步骤、注意事项及学习要点：</p><h3 id="一、爬虫的基本步骤" tabindex="-1">一、爬虫的基本步骤 <a class="header-anchor" href="#一、爬虫的基本步骤" aria-label="Permalink to &quot;一、爬虫的基本步骤&quot;">​</a></h3><p>无论目标是单个网页还是批量数据，爬虫的核心流程可分为三步：</p><h4 id="_1-获取网页内容" tabindex="-1">1. 获取网页内容 <a class="header-anchor" href="#_1-获取网页内容" aria-label="Permalink to &quot;1. 获取网页内容&quot;">​</a></h4><ul><li>原理：通过代码向网站服务器发送 HTTP 请求，服务器返回网页的原始数据（如 HTML、JSON 等）。 <ul><li>与浏览器访问的区别：浏览器会渲染数据为可视化页面，而爬虫获取的是未渲染的原始内容。</li></ul></li><li><strong>工具</strong>：常用 Python 的<code>requests</code>库发送请求，简洁高效。</li></ul><h4 id="_2-解析网页内容" tabindex="-1">2. 解析网页内容 <a class="header-anchor" href="#_2-解析网页内容" aria-label="Permalink to &quot;2. 解析网页内容&quot;">​</a></h4><ul><li><strong>目的</strong>：从海量原始数据中提取目标信息（如商品价格、文章标题等）。</li><li><strong>基础</strong>：需了解 HTML 网页结构（标签、属性等），因为多数网页内容以 HTML 格式返回。</li><li><strong>工具</strong>：使用<code>Beautiful Soup</code>库解析 HTML，快速定位并提取所需数据。</li></ul><h4 id="_3-储存或分析数据" tabindex="-1">3. 储存或分析数据 <a class="header-anchor" href="#_3-储存或分析数据" aria-label="Permalink to &quot;3. 储存或分析数据&quot;">​</a></h4><ul><li>根据需求处理： <ul><li>若需长期使用，可存入数据库（如 MySQL、MongoDB）；</li><li>若需分析趋势，可生成可视化图表（如用<code>matplotlib</code>、<code>pandas</code>）；</li><li>若需舆情监控，可结合 AI 进行文本情感分析等。</li></ul></li><li><strong>扩展</strong>：支持批量爬取（如遍历多个 URL）或深度爬取（从一个网页链接跳转至其他相关页面）。</li></ul><h3 id="二、爬虫的合法合规性-红线与原则" tabindex="-1">二、爬虫的合法合规性：红线与原则 <a class="header-anchor" href="#二、爬虫的合法合规性-红线与原则" aria-label="Permalink to &quot;二、爬虫的合法合规性：红线与原则&quot;">​</a></h3><p>技术本身中立，但需严格遵守规则，避免法律风险：</p><h4 id="_1-绝对禁止爬取的内容" tabindex="-1">1. 绝对禁止爬取的内容 <a class="header-anchor" href="#_1-绝对禁止爬取的内容" aria-label="Permalink to &quot;1. 绝对禁止爬取的内容&quot;">​</a></h4><ul><li>公民隐私数据（如个人信息、账号密码）；</li><li>受著作权保护的内容（如付费文章、原创作品，未经授权不得爬取）；</li><li>涉及国家事务、国防建设、尖端科技等敏感领域的计算机系统数据。</li></ul><h4 id="_2-做-温和的爬虫" tabindex="-1">2. 做 “温和的爬虫” <a class="header-anchor" href="#_2-做-温和的爬虫" aria-label="Permalink to &quot;2. 做 “温和的爬虫”&quot;">​</a></h4><ul><li><strong>控制请求频率</strong>：避免高频、海量请求，防止给服务器造成负担（类似 DDoS 攻击）；</li><li><strong>尊重反爬机制</strong>：不强行突破网站的限制（如登录验证、验证码、IP 封锁等）；</li><li><strong>遵守<code>robots.txt</code>协议</strong>：访问网站根目录下的<code>robots.txt</code>文件（如<code>https://example.com/robots.txt</code>），了解网站允许爬取的范围和限制（部分网站会明确禁止爬虫访问某些路径）。</li></ul><h3 id="三、学习爬虫需掌握的知识" tabindex="-1">三、学习爬虫需掌握的知识 <a class="header-anchor" href="#三、学习爬虫需掌握的知识" aria-label="Permalink to &quot;三、学习爬虫需掌握的知识&quot;">​</a></h3><ol><li><strong>HTTP 请求基础</strong>：理解请求方法（GET/POST）、 headers 等，是发送有效请求的前提；</li><li><strong><code>requests</code>库</strong>：Python 中发送 HTTP 请求的核心工具，需掌握其基本用法；</li><li><strong>HTML 结构</strong>：了解标签、属性、层级关系，才能准确解析网页内容；</li><li><strong><code>Beautiful Soup</code>库</strong>：解析 HTML 的利器，需掌握如何定位和提取数据。</li></ol>',19)])])}const g=t(i,[["render",r]]);export{_ as __pageData,g as default};
