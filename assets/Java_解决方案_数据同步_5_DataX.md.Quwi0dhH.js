import{_ as a,c as e,o as r,ah as l,n4 as i,n5 as d,n6 as s,n7 as n,n8 as o,n9 as b}from"./chunks/framework.D5cOWG0Y.js";const D=JSON.parse('{"title":"DataX","description":"","frontmatter":{"title":"DataX","tags":["数据同步"],"categories":["数据同步"]},"headers":[],"relativePath":"Java/解决方案/数据同步/5_DataX.md","filePath":"Java/解决方案/数据同步/5_DataX.md","lastUpdated":1755802517000}'),h={name:"Java/解决方案/数据同步/5_DataX.md"};function c(p,t,g,m,k,f){return r(),e("div",null,[...t[0]||(t[0]=[l('<p>因为最近使用到了DataX，所以接下来需要来个系统的学习，并以博客的形式记录。</p><h2 id="一-datax3-0概览" tabindex="-1">一. DataX3.0概览 <a class="header-anchor" href="#一-datax3-0概览" aria-label="Permalink to “一. DataX3.0概览”">​</a></h2><p>DataX 是一个异构数据源离线同步工具，致力于实现包括关系型数据库(MySQL、Oracle等)、HDFS、Hive、ODPS、HBase、FTP等各种异构数据源之间稳定高效的数据同步功能。</p><p><img src="'+i+'" alt="datax_why_new" loading="lazy"></p><ul><li><h4 id="设计理念" tabindex="-1">设计理念 <a class="header-anchor" href="#设计理念" aria-label="Permalink to “设计理念”">​</a></h4><p>为了解决异构数据源同步问题，DataX将复杂的网状的同步链路变成了星型数据链路，DataX作为中间传输载体负责连接各种数据源。当需要接入一个新的数据源的时候，只需要将此数据源对接到DataX，便能跟已有的数据源做到无缝数据同步。</p></li><li><h4 id="当前使用现状" tabindex="-1">当前使用现状 <a class="header-anchor" href="#当前使用现状" aria-label="Permalink to “当前使用现状”">​</a></h4><p>DataX在阿里巴巴集团内被广泛使用，承担了所有大数据的离线同步业务，并已持续稳定运行了6年之久。目前每天完成同步8w多道作业，每日传输数据量超过300TB。</p></li></ul><p>目前最新版本是DataX3.0，有了更多更强大的功能和更好的使用体验。</p><h2 id="二、datax3-0框架设计" tabindex="-1">二、DataX3.0框架设计 <a class="header-anchor" href="#二、datax3-0框架设计" aria-label="Permalink to “二、DataX3.0框架设计”">​</a></h2><p><img src="'+d+'" alt="datax_framework_new" loading="lazy"></p><p>DataX本身作为离线数据同步框架，采用Framework + plugin架构构建。将数据源读取和写入抽象成为Reader/Writer插件，纳入到整个同步框架中。</p><ul><li>Reader：Reader为数据采集模块，负责采集数据源的数据，将数据发送给Framework。</li><li>Writer： Writer为数据写入模块，负责不断向Framework取数据，并将数据写入到目的端。</li><li>Framework：Framework用于连接reader和writer，作为两者的数据传输通道，并处理缓冲，流控，并发，数据转换等核心技术问题。</li></ul><h2 id="三-datax3-0插件体系" tabindex="-1">三. DataX3.0插件体系 <a class="header-anchor" href="#三-datax3-0插件体系" aria-label="Permalink to “三. DataX3.0插件体系”">​</a></h2><p>经过几年积累，DataX目前已经有了比较全面的插件体系，主流的RDBMS数据库、NOSQL、大数据计算系统都已经接入。DataX目前支持数据如下：</p><table tabindex="0"><thead><tr><th>类型</th><th>数据源</th><th style="text-align:center;">Reader(读)</th><th style="text-align:center;">Writer(写)</th><th style="text-align:center;">文档</th></tr></thead><tbody><tr><td>RDBMS 关系型数据库</td><td>MySQL</td><td style="text-align:center;">√</td><td style="text-align:center;">√</td><td style="text-align:center;"><a href="https://github.com/alibaba/DataX/blob/master/mysqlreader/doc/mysqlreader.md" target="_blank" rel="noreferrer">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/mysqlwriter/doc/mysqlwriter.md" target="_blank" rel="noreferrer">写</a></td></tr><tr><td></td><td>Oracle</td><td style="text-align:center;">√</td><td style="text-align:center;">√</td><td style="text-align:center;"><a href="https://github.com/alibaba/DataX/blob/master/oraclereader/doc/oraclereader.md" target="_blank" rel="noreferrer">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/oraclewriter/doc/oraclewriter.md" target="_blank" rel="noreferrer">写</a></td></tr><tr><td></td><td>OceanBase</td><td style="text-align:center;">√</td><td style="text-align:center;">√</td><td style="text-align:center;"><a href="https://open.oceanbase.com/docs/community/oceanbase-database/V3.1.0/use-datax-to-full-migration-data-to-oceanbase" target="_blank" rel="noreferrer">读</a> 、<a href="https://open.oceanbase.com/docs/community/oceanbase-database/V3.1.0/use-datax-to-full-migration-data-to-oceanbase" target="_blank" rel="noreferrer">写</a></td></tr><tr><td></td><td>SQLServer</td><td style="text-align:center;">√</td><td style="text-align:center;">√</td><td style="text-align:center;"><a href="https://github.com/alibaba/DataX/blob/master/sqlserverreader/doc/sqlserverreader.md" target="_blank" rel="noreferrer">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/sqlserverwriter/doc/sqlserverwriter.md" target="_blank" rel="noreferrer">写</a></td></tr><tr><td></td><td>PostgreSQL</td><td style="text-align:center;">√</td><td style="text-align:center;">√</td><td style="text-align:center;"><a href="https://github.com/alibaba/DataX/blob/master/postgresqlreader/doc/postgresqlreader.md" target="_blank" rel="noreferrer">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/postgresqlwriter/doc/postgresqlwriter.md" target="_blank" rel="noreferrer">写</a></td></tr><tr><td></td><td>DRDS</td><td style="text-align:center;">√</td><td style="text-align:center;">√</td><td style="text-align:center;"><a href="https://github.com/alibaba/DataX/blob/master/drdsreader/doc/drdsreader.md" target="_blank" rel="noreferrer">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/drdswriter/doc/drdswriter.md" target="_blank" rel="noreferrer">写</a></td></tr><tr><td></td><td>达梦</td><td style="text-align:center;">√</td><td style="text-align:center;">√</td><td style="text-align:center;"><a href="./.html">读</a> 、<a href="./.html">写</a></td></tr><tr><td></td><td>通用RDBMS(支持所有关系型数据库)</td><td style="text-align:center;">√</td><td style="text-align:center;">√</td><td style="text-align:center;"><a href="./.html">读</a> 、<a href="./.html">写</a></td></tr><tr><td>阿里云数仓数据存储</td><td>ODPS</td><td style="text-align:center;">√</td><td style="text-align:center;">√</td><td style="text-align:center;"><a href="https://github.com/alibaba/DataX/blob/master/odpsreader/doc/odpsreader.md" target="_blank" rel="noreferrer">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/odpsswriter/doc/odpswriter.md" target="_blank" rel="noreferrer">写</a></td></tr><tr><td></td><td>ADS</td><td style="text-align:center;"></td><td style="text-align:center;">√</td><td style="text-align:center;"><a href="https://github.com/alibaba/DataX/blob/master/adswriter/doc/adswriter.md" target="_blank" rel="noreferrer">写</a></td></tr><tr><td></td><td>OSS</td><td style="text-align:center;">√</td><td style="text-align:center;">√</td><td style="text-align:center;"><a href="https://github.com/alibaba/DataX/blob/master/ossreader/doc/ossreader.md" target="_blank" rel="noreferrer">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/osswriter/doc/osswriter.md" target="_blank" rel="noreferrer">写</a></td></tr><tr><td></td><td>OCS</td><td style="text-align:center;">√</td><td style="text-align:center;">√</td><td style="text-align:center;"><a href="https://github.com/alibaba/DataX/blob/master/ocsreader/doc/ocsreader.md" target="_blank" rel="noreferrer">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/ocswriter/doc/ocswriter.md" target="_blank" rel="noreferrer">写</a></td></tr><tr><td>NoSQL数据存储</td><td>OTS</td><td style="text-align:center;">√</td><td style="text-align:center;">√</td><td style="text-align:center;"><a href="https://github.com/alibaba/DataX/blob/master/otsreader/doc/otsreader.md" target="_blank" rel="noreferrer">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/otswriter/doc/otswriter.md" target="_blank" rel="noreferrer">写</a></td></tr><tr><td></td><td>Hbase0.94</td><td style="text-align:center;">√</td><td style="text-align:center;">√</td><td style="text-align:center;"><a href="https://github.com/alibaba/DataX/blob/master/hbase094xreader/doc/hbase094xreader.md" target="_blank" rel="noreferrer">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/hbase094xwriter/doc/hbase094xwriter.md" target="_blank" rel="noreferrer">写</a></td></tr><tr><td></td><td>Hbase1.1</td><td style="text-align:center;">√</td><td style="text-align:center;">√</td><td style="text-align:center;"><a href="https://github.com/alibaba/DataX/blob/master/hbase11xreader/doc/hbase11xreader.md" target="_blank" rel="noreferrer">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/hbase11xwriter/doc/hbase11xwriter.md" target="_blank" rel="noreferrer">写</a></td></tr><tr><td></td><td>MongoDB</td><td style="text-align:center;">√</td><td style="text-align:center;">√</td><td style="text-align:center;"><a href="https://github.com/alibaba/DataX/blob/master/mongoreader/doc/mongoreader.md" target="_blank" rel="noreferrer">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/mongowriter/doc/mongowriter.md" target="_blank" rel="noreferrer">写</a></td></tr><tr><td></td><td>Hive</td><td style="text-align:center;">√</td><td style="text-align:center;">√</td><td style="text-align:center;"><a href="https://github.com/alibaba/DataX/blob/master/hdfsreader/doc/hdfsreader.md" target="_blank" rel="noreferrer">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/hdfswriter/doc/hdfswriter.md" target="_blank" rel="noreferrer">写</a></td></tr><tr><td>无结构化数据存储</td><td>TxtFile</td><td style="text-align:center;">√</td><td style="text-align:center;">√</td><td style="text-align:center;"><a href="https://github.com/alibaba/DataX/blob/master/txtfilereader/doc/txtfilereader.md" target="_blank" rel="noreferrer">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/txtfilewriter/doc/txtfilewriter.md" target="_blank" rel="noreferrer">写</a></td></tr><tr><td></td><td>FTP</td><td style="text-align:center;">√</td><td style="text-align:center;">√</td><td style="text-align:center;"><a href="https://github.com/alibaba/DataX/blob/master/ftpreader/doc/ftpreader.md" target="_blank" rel="noreferrer">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/ftpwriter/doc/ftpwriter.md" target="_blank" rel="noreferrer">写</a></td></tr><tr><td></td><td>HDFS</td><td style="text-align:center;">√</td><td style="text-align:center;">√</td><td style="text-align:center;"><a href="https://github.com/alibaba/DataX/blob/master/hdfsreader/doc/hdfsreader.md" target="_blank" rel="noreferrer">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/hdfswriter/doc/hdfswriter.md" target="_blank" rel="noreferrer">写</a></td></tr><tr><td></td><td>Elasticsearch</td><td style="text-align:center;"></td><td style="text-align:center;">√</td><td style="text-align:center;"><a href="https://github.com/alibaba/DataX/blob/master/elasticsearchwriter/doc/elasticsearchwriter.md" target="_blank" rel="noreferrer">写</a></td></tr></tbody></table><p>DataX Framework提供了简单的接口与插件交互，提供简单的插件接入机制，只需要任意加上一种插件，就能无缝对接其他数据源。</p><p>详情请看：<a href="https://github.com/alibaba/DataX/wiki/DataX-all-data-channels" target="_blank" rel="noreferrer">DataX数据源指南</a></p><h2 id="四、datax3-0核心架构" tabindex="-1">四、DataX3.0核心架构 <a class="header-anchor" href="#四、datax3-0核心架构" aria-label="Permalink to “四、DataX3.0核心架构”">​</a></h2><p>DataX 3.0 开源版本支持单机多线程模式完成同步作业运行，本小节按一个DataX作业生命周期的时序图，从整体架构设计非常简要说明DataX各个模块相互关系。</p><p><img src="'+s+`" alt="datax_arch" loading="lazy"></p><h4 id="核心模块介绍" tabindex="-1">核心模块介绍： <a class="header-anchor" href="#核心模块介绍" aria-label="Permalink to “核心模块介绍：”">​</a></h4><ol><li>DataX完成单个数据同步的作业，我们称之为Job，DataX接受到一个Job之后，将启动一个进程来完成整个作业同步过程。DataX Job模块是单个作业的中枢管理节点，承担了数据清理、子任务切分(将单一作业计算转化为多个子Task)、TaskGroup管理等功能。</li><li>DataXJob启动后，会根据不同的源端切分策略，将Job切分成多个小的Task(子任务)，以便于并发执行。Task便是DataX作业的最小单元，每一个Task都会负责一部分数据的同步工作。</li><li>切分多个Task之后，DataX Job会调用Scheduler模块，根据配置的并发数据量，将拆分成的Task重新组合，组装成TaskGroup(任务组)。每一个TaskGroup负责以一定的并发运行完毕分配好的所有Task，默认单个任务组的并发数量为5。</li><li>每一个Task都由TaskGroup负责启动，Task启动后，会固定启动Reader—&gt;Channel—&gt;Writer的线程来完成任务同步工作。</li><li>DataX作业运行起来之后， Job监控并等待多个TaskGroup模块任务完成，等待所有TaskGroup任务完成后Job成功退出。否则，异常退出，进程退出值非0</li></ol><h4 id="datax调度流程" tabindex="-1">DataX调度流程： <a class="header-anchor" href="#datax调度流程" aria-label="Permalink to “DataX调度流程：”">​</a></h4><p>举例来说，用户提交了一个DataX作业，并且配置了20个并发，目的是将一个100张分表的mysql数据同步到odps里面。 DataX的调度决策思路是：</p><ol><li>DataXJob根据分库分表切分成了100个Task。</li><li>根据20个并发，DataX计算共需要分配4个TaskGroup。</li><li>4个TaskGroup平分切分好的100个Task，每一个TaskGroup负责以5个并发共计运行25个Task。</li></ol><h2 id="五、datax-3-0六大核心优势" tabindex="-1">五、DataX 3.0六大核心优势 <a class="header-anchor" href="#五、datax-3-0六大核心优势" aria-label="Permalink to “五、DataX 3.0六大核心优势”">​</a></h2><ul><li><h4 id="可靠的数据质量监控" tabindex="-1">可靠的数据质量监控 <a class="header-anchor" href="#可靠的数据质量监控" aria-label="Permalink to “可靠的数据质量监控”">​</a></h4><ul><li><p>完美解决数据传输个别类型失真问题</p><p>DataX旧版对于部分数据类型(比如时间戳)传输一直存在毫秒阶段等数据失真情况，新版本DataX3.0已经做到支持所有的强数据类型，每一种插件都有自己的数据类型转换策略，让数据可以完整无损的传输到目的端。</p></li><li><p>提供作业全链路的流量、数据量运行时监控</p><p>DataX3.0运行过程中可以将作业本身状态、数据流量、数据速度、执行进度等信息进行全面的展示，让用户可以实时了解作业状态。并可在作业执行过程中智能判断源端和目的端的速度对比情况，给予用户更多性能排查信息。</p></li><li><p>提供脏数据探测</p><p>在大量数据的传输过程中，必定会由于各种原因导致很多数据传输报错(比如类型转换错误)，这种数据DataX认为就是脏数据。DataX目前可以实现脏数据精确过滤、识别、采集、展示，为用户提供多种的脏数据处理模式，让用户准确把控数据质量大关！</p></li></ul></li><li><h4 id="丰富的数据转换功能" tabindex="-1">丰富的数据转换功能 <a class="header-anchor" href="#丰富的数据转换功能" aria-label="Permalink to “丰富的数据转换功能”">​</a></h4><p>DataX作为一个服务于大数据的ETL工具，除了提供数据快照搬迁功能之外，还提供了丰富数据转换的功能，让数据在传输过程中可以轻松完成数据脱敏，补全，过滤等数据转换功能，另外还提供了自动groovy函数，让用户自定义转换函数。详情请看DataX3的transformer详细介绍。</p></li><li><h4 id="精准的速度控制" tabindex="-1">精准的速度控制 <a class="header-anchor" href="#精准的速度控制" aria-label="Permalink to “精准的速度控制”">​</a></h4><p>还在为同步过程对在线存储压力影响而担心吗？新版本DataX3.0提供了包括通道(并发)、记录流、字节流三种流控模式，可以随意控制你的作业速度，让你的作业在库可以承受的范围内达到最佳的同步速度。</p><div class="language-json line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">json</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;speed&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">   &quot;channel&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">   &quot;byte&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1048576</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">   &quot;record&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10000</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div></li><li><h4 id="强劲的同步性能" tabindex="-1">强劲的同步性能 <a class="header-anchor" href="#强劲的同步性能" aria-label="Permalink to “强劲的同步性能”">​</a></h4><p>DataX3.0每一种读插件都有一种或多种切分策略，都能将作业合理切分成多个Task并行执行，单机多线程执行模型可以让DataX速度随并发成线性增长。在源端和目的端性能都足够的情况下，单个作业一定可以打满网卡。另外，DataX团队对所有的已经接入的插件都做了极致的性能优化，并且做了完整的性能测试。性能测试相关详情可以参照每单个数据源的详细介绍：<a href="https://github.com/alibaba/DataX/wiki/DataX-all-data-channels" target="_blank" rel="noreferrer">DataX数据源指南</a></p></li><li><h4 id="健壮的容错机制" tabindex="-1">健壮的容错机制 <a class="header-anchor" href="#健壮的容错机制" aria-label="Permalink to “健壮的容错机制”">​</a></h4><p>DataX作业是极易受外部因素的干扰，网络闪断、数据源不稳定等因素很容易让同步到一半的作业报错停止。因此稳定性是DataX的基本要求，在DataX 3.0的设计中，重点完善了框架和插件的稳定性。目前DataX3.0可以做到线程级别、进程级别(暂时未开放)、作业级别多层次局部/全局的重试，保证用户的作业稳定运行。</p><ul><li><p>线程内部重试</p><p>DataX的核心插件都经过团队的全盘review，不同的网络交互方式都有不同的重试策略。</p></li><li><p>线程级别重试</p><p>目前DataX已经可以实现TaskFailover，针对于中间失败的Task，DataX框架可以做到整个Task级别的重新调度。</p></li></ul></li><li><h4 id="极简的使用体验" tabindex="-1">极简的使用体验 <a class="header-anchor" href="#极简的使用体验" aria-label="Permalink to “极简的使用体验”">​</a></h4><ul><li><p>易用</p><p>下载即可用，支持linux和windows，只需要短短几步骤就可以完成数据的传输。请点击：<a href="https://github.com/alibaba/DataX/wiki/Quick-Start" target="_blank" rel="noreferrer">Quick Start</a></p></li><li><p>详细</p><p>DataX在运行日志中打印了大量信息，其中包括传输速度，Reader、Writer性能，进程CPU，JVM和GC情况等等。</p><ul><li><p>传输过程中打印传输速度、进度等</p><p><img src="`+n+'" alt="datax_run_speed" loading="lazy"></p></li><li><p>传输过程中会打印进程相关的CPU、JVM等</p><p><img src="'+o+'" alt="datax_run_cpu" loading="lazy"></p></li><li><p>在任务结束之后，打印总体运行情况</p><p><img src="'+b+'" alt="datax_end_info" loading="lazy"></p></li></ul></li></ul></li></ul><p><a href="https://developer.aliyun.com/article/1045779" target="_blank" rel="noreferrer">https://developer.aliyun.com/article/1045779</a></p>',26)])])}const y=a(h,[["render",c]]);export{D as __pageData,y as default};
