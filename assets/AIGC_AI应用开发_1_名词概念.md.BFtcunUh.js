import{_ as e,c as t,o as a,aN as l}from"./chunks/framework.CMIDsdwV.js";const h=JSON.parse('{"title":"名词概念","description":"","frontmatter":{"title":"名词概念","date":"2026-02-06","permalink":"/aigc/development/Introduction","tags":["AI应用开发"],"categories":["AI应用开发"]},"headers":[],"relativePath":"AIGC/AI应用开发/1_名词概念.md","filePath":"AIGC/AI应用开发/1_名词概念.md","lastUpdated":1770802223000}'),o={name:"AIGC/AI应用开发/1_名词概念.md"};function i(n,r,s,u,g,p){return a(),t("div",null,[...r[0]||(r[0]=[l('<div style="display:none;" hidden="true" aria-hidden="true">Are you an LLM? You can read better optimized documentation at /AIGC\\AI应用开发\\1_名词概念.md for this page in Markdown format</div><h1 id="名词概念" tabindex="-1">名词概念 <a class="header-anchor" href="#名词概念" aria-label="Permalink to &quot;名词概念&quot;">​</a></h1><ul><li><p><strong>Skill（技能）</strong>：AI模型能够执行的特定任务或功能，如文本生成、图像处理、数据分析等。技能通常是通过训练或编程实现的，使AI系统能够完成特定领域的工作。</p></li><li><p><strong>MCP（Model Calling Protocol）</strong>：模型调用协议，定义了如何与AI模型进行通信和交互的标准规范。它确保了不同系统和模型之间的互操作性，简化了AI应用的开发和集成。</p></li><li><p><strong>RAG（Retrieval-Augmented Generation）</strong>：检索增强生成，一种结合了信息检索和生成式AI的技术。它通过在生成回答前先检索相关信息，提高了AI模型回答的准确性和可靠性，减少了幻觉现象。</p><ul><li>相关论文：Lewis, P., et al. (2020). &quot;Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.&quot; NeurIPS. <a href="https://arxiv.org/abs/2005.11401" target="_blank" rel="noreferrer">论文链接</a></li></ul></li><li><p><strong>Agent（智能体）</strong>：能够自主执行任务并做出决策的AI系统。智能体通常具有感知环境、制定计划、执行行动和学习改进的能力，可以独立或协作完成复杂任务。</p><ul><li>相关论文：Russell, S., &amp; Norvig, P. (2010). &quot;Artificial Intelligence: A Modern Approach.&quot; Prentice Hall.（经典教材，系统介绍智能体概念）</li></ul></li><li><p><strong>OpenClaw / Clawdbot（开源项目）</strong>：一个开源的AI应用开发框架，提供了构建智能机器人和自动化系统的工具和组件。它支持多种AI模型和集成方式，简化了AI应用的开发流程。</p></li><li><p><strong>LLM（Large Language Model）</strong>：大型语言模型，如GPT、Claude等，通过大规模文本训练获得的能够理解和生成人类语言的AI模型。它们是现代AI应用的核心组件之一。</p><ul><li>相关论文： <ul><li>Brown, T. B., et al. (2020). &quot;Language Models are Few-Shot Learners.&quot; NeurIPS.（GPT-3）<a href="https://arxiv.org/abs/2005.14165" target="_blank" rel="noreferrer">论文链接</a></li><li>Ouyang, L., et al. (2022). &quot;Training language models to follow instructions with human feedback.&quot; NeurIPS.（InstructGPT）<a href="https://arxiv.org/abs/2203.02155" target="_blank" rel="noreferrer">论文链接</a></li></ul></li></ul></li><li><p><strong>API（Application Programming Interface）</strong>：应用程序编程接口，定义了软件组件之间的交互方式。在AI领域，API通常用于访问AI模型的功能，如文本生成、图像处理等。</p></li><li><p><strong>Fine-tuning（微调）</strong>：针对特定任务或领域，对预训练模型进行进一步训练的过程。微调可以提高模型在特定任务上的性能，使其更适合特定应用场景。</p><ul><li>相关论文：Howard, J., &amp; Ruder, S. (2018). &quot;Universal Language Model Fine-tuning for Text Classification.&quot; ACL.（ULMFiT，开创了预训练+微调范式）<a href="https://arxiv.org/abs/1801.06146" target="_blank" rel="noreferrer">论文链接</a></li></ul></li><li><p><strong>Embedding（嵌入）</strong>：将文本、图像等数据转换为向量表示的过程。嵌入向量能够捕捉数据的语义信息，是许多AI任务（如检索、分类）的基础。</p><ul><li>相关论文：Mikolov, T., et al. (2013). &quot;Efficient Estimation of Word Representations in Vector Space.&quot; arXiv preprint arXiv:1301.3781.（Word2Vec，经典词嵌入方法）<a href="https://arxiv.org/abs/1301.3781" target="_blank" rel="noreferrer">论文链接</a></li></ul></li><li><p><strong>Prompt Engineering（提示工程）</strong>：设计和优化提示语句的过程，以引导AI模型产生更准确、相关的输出。提示工程是充分发挥LLM能力的关键技术之一。</p><ul><li>相关论文：Liu, P., et al. (2021). &quot;Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing.&quot; arXiv preprint arXiv:2107.13586.（提示学习综述）<a href="https://arxiv.org/abs/2107.13586" target="_blank" rel="noreferrer">论文链接</a></li></ul></li><li><p><strong>Token（令牌）</strong>：AI模型处理文本的基本单位，通常是单词、部分单词或字符。模型的上下文窗口大小和生成能力通常以令牌数量来衡量。</p><ul><li>相关论文：Sennrich, R., Haddow, B., &amp; Birch, A. (2016). &quot;Neural Machine Translation of Rare Words with Subword Units.&quot; ACL.（子词分词方法）<a href="https://arxiv.org/abs/1508.07909" target="_blank" rel="noreferrer">论文链接</a></li></ul></li><li><p><strong>Context Window（上下文窗口）</strong>：AI模型能够同时处理的令牌数量上限。更大的上下文窗口允许模型考虑更多的上下文信息，提高理解和生成的质量。</p><ul><li>相关论文：OpenAI. (2023). &quot;GPT-4 Technical Report.&quot;（介绍大上下文窗口能力）<a href="https://arxiv.org/abs/2303.08774" target="_blank" rel="noreferrer">报告链接</a></li></ul></li><li><p><strong>Temperature（温度参数）</strong>：控制AI模型生成文本随机性的参数。较高的温度值会产生更多样化但可能不太准确的输出，较低的温度值会产生更确定但可能更保守的输出。</p><ul><li>相关论文：Holzinger, A., et al. (2023). &quot;Explainable AI: Foundations, Applications, and Challenges.&quot; Springer.（讨论生成参数对输出的影响）</li></ul></li><li><p><strong>Top-k/Top-p Sampling（采样策略）</strong>：控制AI模型生成文本时选择下一个令牌的策略。Top-k限制只从概率最高的k个令牌中选择，Top-p限制只从累积概率达到p的令牌中选择。</p><ul><li>相关论文：Holtzman, A., et al. (2020). &quot;The Curious Case of Neural Text Degeneration.&quot; ICLR.（比较不同采样策略）<a href="https://arxiv.org/abs/1904.09751" target="_blank" rel="noreferrer">论文链接</a></li></ul></li><li><p><strong>Chain-of-Thought（思维链）</strong>：一种提示技术，通过引导AI模型逐步思考和推理，提高其解决复杂问题的能力。思维链提示通常包含中间推理步骤，帮助模型更好地理解问题。</p><ul><li>相关论文：Wei, J., et al. (2022). &quot;Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.&quot; NeurIPS. <a href="https://arxiv.org/abs/2201.11903" target="_blank" rel="noreferrer">论文链接</a></li></ul></li><li><p><strong>Vector Database（向量数据库）</strong>：专门用于存储和检索嵌入向量的数据库系统。向量数据库通过近似最近邻（ANN）算法，实现了高效的相似性搜索，是RAG等技术的重要组成部分。</p><ul><li>相关论文：Johnson, J., Douze, M., &amp; Jégou, H. (2017). &quot;Billion-scale similarity search with GPUs.&quot; IEEE Transactions on Big Data.（FAISS，经典向量检索库）<a href="https://arxiv.org/abs/1702.08734" target="_blank" rel="noreferrer">论文链接</a></li></ul></li><li><p><strong>Hallucination（幻觉）</strong>：AI模型生成的内容与事实不符或不存在的现象。幻觉是生成式AI的一个常见问题，RAG等技术可以帮助减少幻觉的发生。</p><ul><li>相关论文：Ji, Y., et al. (2023). &quot;Survey of Hallucination in Natural Language Generation.&quot; ACM Computing Surveys. <a href="https://arxiv.org/abs/2209.07275" target="_blank" rel="noreferrer">论文链接</a></li></ul></li><li><p><strong>Multimodal（多模态）</strong>：能够处理和理解多种类型数据（如文本、图像、音频、视频）的AI系统。多模态模型可以实现跨模态的理解和生成，如根据文本描述生成图像，或根据图像内容生成描述。</p><ul><li>相关论文：Radford, A., et al. (2021). &quot;Learning Transferable Visual Models From Natural Language Supervision.&quot; ICML.（CLIP，多模态预训练模型）<a href="https://arxiv.org/abs/2103.00020" target="_blank" rel="noreferrer">论文链接</a></li></ul></li><li><p><strong>Few-shot/Zero-shot Learning（少样本/零样本学习）</strong>：AI模型在仅提供少量（甚至没有）示例的情况下，就能理解和执行新任务的能力。这种能力使得模型能够更灵活地适应新的应用场景。</p><ul><li>相关论文： <ul><li>Brown, T. B., et al. (2020). &quot;Language Models are Few-Shot Learners.&quot; NeurIPS.（GPT-3，展示少样本能力）<a href="https://arxiv.org/abs/2005.14165" target="_blank" rel="noreferrer">论文链接</a></li><li>Lake, B. M., et al. (2015). &quot;Human-level concept learning through probabilistic program induction.&quot; Science.（人类少样本学习机制）<a href="https://www.science.org/doi/10.1126/science.aab3050" target="_blank" rel="noreferrer">论文链接</a></li></ul></li></ul></li><li><p><strong>Reinforcement Learning from Human Feedback（RLHF）</strong>：基于人类反馈的强化学习，一种通过人类反馈来优化AI模型行为的技术。RLHF可以使模型的输出更符合人类的偏好和价值观。</p><ul><li>相关论文：Ouyang, L., et al. (2022). &quot;Training language models to follow instructions with human feedback.&quot; NeurIPS.（InstructGPT，RLHF在LLM中的应用）<a href="https://arxiv.org/abs/2203.02155" target="_blank" rel="noreferrer">论文链接</a></li></ul></li></ul>',3)])])}const c=e(o,[["render",i]]);export{h as __pageData,c as default};
