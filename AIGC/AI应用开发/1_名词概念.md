---
url: /AIGC/AI应用开发/1_名词概念.md
---

# 名词概念

* **Skill（技能）**：AI模型能够执行的特定任务或功能，如文本生成、图像处理、数据分析等。技能通常是通过训练或编程实现的，使AI系统能够完成特定领域的工作。

* **MCP（Model Calling Protocol）**：模型调用协议，定义了如何与AI模型进行通信和交互的标准规范。它确保了不同系统和模型之间的互操作性，简化了AI应用的开发和集成。

* **RAG（Retrieval-Augmented Generation）**：检索增强生成，一种结合了信息检索和生成式AI的技术。它通过在生成回答前先检索相关信息，提高了AI模型回答的准确性和可靠性，减少了幻觉现象。
  * 相关论文：Lewis, P., et al. (2020). "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks." NeurIPS. [论文链接](https://arxiv.org/abs/2005.11401)

* **Agent（智能体）**：能够自主执行任务并做出决策的AI系统。智能体通常具有感知环境、制定计划、执行行动和学习改进的能力，可以独立或协作完成复杂任务。
  * 相关论文：Russell, S., & Norvig, P. (2010). "Artificial Intelligence: A Modern Approach." Prentice Hall.（经典教材，系统介绍智能体概念）

* **OpenClaw / Clawdbot（开源项目）**：一个开源的AI应用开发框架，提供了构建智能机器人和自动化系统的工具和组件。它支持多种AI模型和集成方式，简化了AI应用的开发流程。

* **LLM（Large Language Model）**：大型语言模型，如GPT、Claude等，通过大规模文本训练获得的能够理解和生成人类语言的AI模型。它们是现代AI应用的核心组件之一。
  * 相关论文：
    * Brown, T. B., et al. (2020). "Language Models are Few-Shot Learners." NeurIPS.（GPT-3）[论文链接](https://arxiv.org/abs/2005.14165)
    * Ouyang, L., et al. (2022). "Training language models to follow instructions with human feedback." NeurIPS.（InstructGPT）[论文链接](https://arxiv.org/abs/2203.02155)

* **API（Application Programming Interface）**：应用程序编程接口，定义了软件组件之间的交互方式。在AI领域，API通常用于访问AI模型的功能，如文本生成、图像处理等。

* **Fine-tuning（微调）**：针对特定任务或领域，对预训练模型进行进一步训练的过程。微调可以提高模型在特定任务上的性能，使其更适合特定应用场景。
  * 相关论文：Howard, J., & Ruder, S. (2018). "Universal Language Model Fine-tuning for Text Classification." ACL.（ULMFiT，开创了预训练+微调范式）[论文链接](https://arxiv.org/abs/1801.06146)

* **Embedding（嵌入）**：将文本、图像等数据转换为向量表示的过程。嵌入向量能够捕捉数据的语义信息，是许多AI任务（如检索、分类）的基础。
  * 相关论文：Mikolov, T., et al. (2013). "Efficient Estimation of Word Representations in Vector Space." arXiv preprint arXiv:1301.3781.（Word2Vec，经典词嵌入方法）[论文链接](https://arxiv.org/abs/1301.3781)

* **Prompt Engineering（提示工程）**：设计和优化提示语句的过程，以引导AI模型产生更准确、相关的输出。提示工程是充分发挥LLM能力的关键技术之一。
  * 相关论文：Liu, P., et al. (2021). "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing." arXiv preprint arXiv:2107.13586.（提示学习综述）[论文链接](https://arxiv.org/abs/2107.13586)

* **Token（令牌）**：AI模型处理文本的基本单位，通常是单词、部分单词或字符。模型的上下文窗口大小和生成能力通常以令牌数量来衡量。
  * 相关论文：Sennrich, R., Haddow, B., & Birch, A. (2016). "Neural Machine Translation of Rare Words with Subword Units." ACL.（子词分词方法）[论文链接](https://arxiv.org/abs/1508.07909)

* **Context Window（上下文窗口）**：AI模型能够同时处理的令牌数量上限。更大的上下文窗口允许模型考虑更多的上下文信息，提高理解和生成的质量。
  * 相关论文：OpenAI. (2023). "GPT-4 Technical Report."（介绍大上下文窗口能力）[报告链接](https://arxiv.org/abs/2303.08774)

* **Temperature（温度参数）**：控制AI模型生成文本随机性的参数。较高的温度值会产生更多样化但可能不太准确的输出，较低的温度值会产生更确定但可能更保守的输出。
  * 相关论文：Holzinger, A., et al. (2023). "Explainable AI: Foundations, Applications, and Challenges." Springer.（讨论生成参数对输出的影响）

* **Top-k/Top-p Sampling（采样策略）**：控制AI模型生成文本时选择下一个令牌的策略。Top-k限制只从概率最高的k个令牌中选择，Top-p限制只从累积概率达到p的令牌中选择。
  * 相关论文：Holtzman, A., et al. (2020). "The Curious Case of Neural Text Degeneration." ICLR.（比较不同采样策略）[论文链接](https://arxiv.org/abs/1904.09751)

* **Chain-of-Thought（思维链）**：一种提示技术，通过引导AI模型逐步思考和推理，提高其解决复杂问题的能力。思维链提示通常包含中间推理步骤，帮助模型更好地理解问题。
  * 相关论文：Wei, J., et al. (2022). "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models." NeurIPS. [论文链接](https://arxiv.org/abs/2201.11903)

* **Vector Database（向量数据库）**：专门用于存储和检索嵌入向量的数据库系统。向量数据库通过近似最近邻（ANN）算法，实现了高效的相似性搜索，是RAG等技术的重要组成部分。
  * 相关论文：Johnson, J., Douze, M., & Jégou, H. (2017). "Billion-scale similarity search with GPUs." IEEE Transactions on Big Data.（FAISS，经典向量检索库）[论文链接](https://arxiv.org/abs/1702.08734)

* **Hallucination（幻觉）**：AI模型生成的内容与事实不符或不存在的现象。幻觉是生成式AI的一个常见问题，RAG等技术可以帮助减少幻觉的发生。
  * 相关论文：Ji, Y., et al. (2023). "Survey of Hallucination in Natural Language Generation." ACM Computing Surveys. [论文链接](https://arxiv.org/abs/2209.07275)

* **Multimodal（多模态）**：能够处理和理解多种类型数据（如文本、图像、音频、视频）的AI系统。多模态模型可以实现跨模态的理解和生成，如根据文本描述生成图像，或根据图像内容生成描述。
  * 相关论文：Radford, A., et al. (2021). "Learning Transferable Visual Models From Natural Language Supervision." ICML.（CLIP，多模态预训练模型）[论文链接](https://arxiv.org/abs/2103.00020)

* **Few-shot/Zero-shot Learning（少样本/零样本学习）**：AI模型在仅提供少量（甚至没有）示例的情况下，就能理解和执行新任务的能力。这种能力使得模型能够更灵活地适应新的应用场景。
  * 相关论文：
    * Brown, T. B., et al. (2020). "Language Models are Few-Shot Learners." NeurIPS.（GPT-3，展示少样本能力）[论文链接](https://arxiv.org/abs/2005.14165)
    * Lake, B. M., et al. (2015). "Human-level concept learning through probabilistic program induction." Science.（人类少样本学习机制）[论文链接](https://www.science.org/doi/10.1126/science.aab3050)

* **Reinforcement Learning from Human Feedback（RLHF）**：基于人类反馈的强化学习，一种通过人类反馈来优化AI模型行为的技术。RLHF可以使模型的输出更符合人类的偏好和价值观。
  * 相关论文：Ouyang, L., et al. (2022). "Training language models to follow instructions with human feedback." NeurIPS.（InstructGPT，RLHF在LLM中的应用）[论文链接](https://arxiv.org/abs/2203.02155)
